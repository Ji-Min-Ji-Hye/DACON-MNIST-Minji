{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: segmentation-models in c:\\users\\user\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: efficientnet==1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from segmentation-models) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications<=1.0.8,>=1.0.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from segmentation-models) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: image-classifiers==1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from segmentation-models) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-image in c:\\users\\user\\anaconda3\\lib\\site-packages (from efficientnet==1.0.0->segmentation-models) (0.16.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.1.3)\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.0.0)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.4.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (45.2.0.post20200210)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U segmentation-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers # L2규제\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, CSVLogger, TensorBoard\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # data augmentation\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler # callbacks 설정\n",
    "\n",
    "from tqdm.notebook import tqdm # 모델학습 진행 시간 파악\n",
    "import random # random seed를 뽑을때 사용\n",
    "\n",
    "import efficientnet.tfkeras as efn \n",
    "from efficientnet.tfkeras import EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0 2.4.3\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__,keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 45\n",
    "img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
    "digit = train.loc[idx, 'digit']\n",
    "letter = train.loc[idx, 'letter']\n",
    "\n",
    "plt.title('Index: %i, Digit: %s, Letter: %s'%(idx, digit, letter))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## efficientnet에 넣어지게 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1차원을 3차원으로 만들어주는 함수\n",
    "def changeChannel(image):\n",
    "    input_ = Input((28,28,1))\n",
    "    conv2d = Conv2D(3, 1, use_bias=False,name=\"conv2d\")\n",
    "    out1 = conv2d(input_)\n",
    "    out1.trainable = False\n",
    "    model1=Model(input_, out1)\n",
    "    print(model1.summary())\n",
    "    model1.layers[1].set_weights([np.ones(([1, 1, 1, 3]))/3])\n",
    "    \n",
    "    res = model1.predict(image)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(['id', 'digit', 'letter'], axis=1).values\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_train = x_train/255\n",
    "\n",
    "y = train['digit']\n",
    "y_train = np.zeros((len(y), len(y.unique())))\n",
    "for i, digit in enumerate(y):\n",
    "    y_train[i, digit] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 28, 28, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 3)         3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x_train_3=changeChannel(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 28, 28, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.00392157],\n",
       "         [0.00392157],\n",
       "         [0.00392157],\n",
       "         ...,\n",
       "         [0.00784314],\n",
       "         [0.        ],\n",
       "         [0.01568627]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.00392157],\n",
       "         [0.01176471],\n",
       "         ...,\n",
       "         [0.01568627],\n",
       "         [0.00392157],\n",
       "         [0.01176471]],\n",
       "\n",
       "        [[0.00784314],\n",
       "         [0.        ],\n",
       "         [0.01568627],\n",
       "         ...,\n",
       "         [0.01176471],\n",
       "         [0.01176471],\n",
       "         [0.01176471]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314],\n",
       "         [0.00392157],\n",
       "         [0.00784314],\n",
       "         ...,\n",
       "         [0.01568627],\n",
       "         [0.00392157],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.01176471],\n",
       "         [0.01176471],\n",
       "         [0.01176471],\n",
       "         ...,\n",
       "         [0.01176471],\n",
       "         [0.01176471],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.01176471],\n",
       "         [0.00784314],\n",
       "         [0.00784314],\n",
       "         ...,\n",
       "         [0.01568627],\n",
       "         [0.01176471],\n",
       "         [0.01568627]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.01568627],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.00392157],\n",
       "         [0.01568627],\n",
       "         [0.00784314]],\n",
       "\n",
       "        [[0.01176471],\n",
       "         [0.01176471],\n",
       "         [0.01568627],\n",
       "         ...,\n",
       "         [0.01176471],\n",
       "         [0.01568627],\n",
       "         [0.00784314]],\n",
       "\n",
       "        [[0.00392157],\n",
       "         [0.01568627],\n",
       "         [0.00784314],\n",
       "         ...,\n",
       "         [0.01568627],\n",
       "         [0.        ],\n",
       "         [0.01568627]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314],\n",
       "         [0.01568627],\n",
       "         [0.01568627],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.00392157]],\n",
       "\n",
       "        [[0.01176471],\n",
       "         [0.00392157],\n",
       "         [0.01568627],\n",
       "         ...,\n",
       "         [0.00784314],\n",
       "         [0.00784314],\n",
       "         [0.01568627]],\n",
       "\n",
       "        [[0.00784314],\n",
       "         [0.00392157],\n",
       "         [0.00392157],\n",
       "         ...,\n",
       "         [0.00784314],\n",
       "         [0.00392157],\n",
       "         [0.00784314]]],\n",
       "\n",
       "\n",
       "       [[[0.00392157],\n",
       "         [0.00392157],\n",
       "         [0.00784314],\n",
       "         ...,\n",
       "         [0.00784314],\n",
       "         [0.01568627],\n",
       "         [0.00392157]],\n",
       "\n",
       "        [[0.00392157],\n",
       "         [0.00784314],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.00784314],\n",
       "         [0.01568627],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.01568627],\n",
       "         [0.00784314],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.00392157],\n",
       "         [0.01176471],\n",
       "         [0.01176471]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.01176471],\n",
       "         [0.        ],\n",
       "         [0.00392157],\n",
       "         ...,\n",
       "         [0.00784314],\n",
       "         [0.00784314],\n",
       "         [0.00392157]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.01176471],\n",
       "         [0.00784314],\n",
       "         ...,\n",
       "         [0.01568627],\n",
       "         [0.00784314],\n",
       "         [0.01176471]],\n",
       "\n",
       "        [[0.01568627],\n",
       "         [0.01568627],\n",
       "         [0.01568627],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.00784314],\n",
       "         [0.00784314]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.01568627],\n",
       "         [0.        ],\n",
       "         [0.01568627],\n",
       "         ...,\n",
       "         [0.01176471],\n",
       "         [0.00784314],\n",
       "         [0.01176471]],\n",
       "\n",
       "        [[0.01568627],\n",
       "         [0.01176471],\n",
       "         [0.00392157],\n",
       "         ...,\n",
       "         [0.01568627],\n",
       "         [0.01568627],\n",
       "         [0.01568627]],\n",
       "\n",
       "        [[0.01176471],\n",
       "         [0.00784314],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.00392157],\n",
       "         [0.01176471],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.01568627],\n",
       "         [0.        ],\n",
       "         [0.01568627],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.00784314],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.01568627],\n",
       "         [0.01176471],\n",
       "         [0.00392157],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.01568627],\n",
       "         [0.01568627]],\n",
       "\n",
       "        [[0.00392157],\n",
       "         [0.01176471],\n",
       "         [0.01176471],\n",
       "         ...,\n",
       "         [0.00784314],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.00784314],\n",
       "         [0.01176471],\n",
       "         [0.01176471],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.00392157],\n",
       "         [0.00784314]],\n",
       "\n",
       "        [[0.01568627],\n",
       "         [0.00392157],\n",
       "         [0.01568627],\n",
       "         ...,\n",
       "         [0.01568627],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.01176471],\n",
       "         [0.00392157],\n",
       "         [0.01176471],\n",
       "         ...,\n",
       "         [0.01176471],\n",
       "         [0.01176471],\n",
       "         [0.01176471]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00392157],\n",
       "         [0.00392157],\n",
       "         [0.01568627],\n",
       "         ...,\n",
       "         [0.00392157],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.01568627],\n",
       "         [0.01568627],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.00392157],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.00392157],\n",
       "         [0.        ],\n",
       "         [0.00392157],\n",
       "         ...,\n",
       "         [0.01568627],\n",
       "         [0.01176471],\n",
       "         [0.00392157]]],\n",
       "\n",
       "\n",
       "       [[[0.01568627],\n",
       "         [0.00784314],\n",
       "         [0.00784314],\n",
       "         ...,\n",
       "         [0.01176471],\n",
       "         [0.00392157],\n",
       "         [0.00784314]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.00784314],\n",
       "         [0.01568627],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.01176471],\n",
       "         [0.01176471]],\n",
       "\n",
       "        [[0.01568627],\n",
       "         [0.00392157],\n",
       "         [0.01568627],\n",
       "         ...,\n",
       "         [0.01568627],\n",
       "         [0.01568627],\n",
       "         [0.01568627]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.00784314],\n",
       "         ...,\n",
       "         [0.01176471],\n",
       "         [0.00784314],\n",
       "         [0.00784314]],\n",
       "\n",
       "        [[0.00784314],\n",
       "         [0.01176471],\n",
       "         [0.00784314],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.00392157],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.01176471],\n",
       "         [0.01176471],\n",
       "         ...,\n",
       "         [0.01568627],\n",
       "         [0.01176471],\n",
       "         [0.01568627]]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00522876, 0.00522876, 0.00522876]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00392157, 0.00392157, 0.00392157]],\n",
       "\n",
       "        [[0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00522876, 0.00522876, 0.00522876]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00261438, 0.00261438, 0.00261438]],\n",
       "\n",
       "        [[0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00261438, 0.00261438, 0.00261438]],\n",
       "\n",
       "        [[0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00522876, 0.00522876, 0.00522876]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00130719, 0.00130719, 0.00130719]],\n",
       "\n",
       "        [[0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00522876, 0.00522876, 0.00522876]],\n",
       "\n",
       "        [[0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00261438, 0.00261438, 0.00261438]]],\n",
       "\n",
       "\n",
       "       [[[0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00130719, 0.00130719, 0.00130719]],\n",
       "\n",
       "        [[0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00130719, 0.00130719, 0.00130719]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00392157, 0.00392157, 0.00392157]],\n",
       "\n",
       "        [[0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00261438, 0.00261438, 0.00261438]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00392157, 0.00392157, 0.00392157]],\n",
       "\n",
       "        [[0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00522876, 0.00522876, 0.00522876]],\n",
       "\n",
       "        [[0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00522876, 0.00522876, 0.00522876]],\n",
       "\n",
       "        [[0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00261438, 0.00261438, 0.00261438]],\n",
       "\n",
       "        [[0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00130719, 0.00130719, 0.00130719]]],\n",
       "\n",
       "\n",
       "       [[[0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00261438, 0.00261438, 0.00261438]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157]],\n",
       "\n",
       "        [[0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00522876, 0.00522876, 0.00522876]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00261438, 0.00261438, 0.00261438]],\n",
       "\n",
       "        [[0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00522876, 0.00522876, 0.00522876]]]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_3\n",
    "# x_train과 비교했을 때 값이 달라지는군..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding\n",
    "#https://stackoverflow.com/questions/61309432/padding-mnist-images-from-28-28-1-to-32-32-1\n",
    "x_train_32=np.pad(x_train_3,((0,0),(2,2),(2,2),(0,0)),'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 32, 32, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         ...,\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         ...,\n",
       "         [0.00130719, 0.00130719, 0.00130719],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         ...,\n",
       "         [0.00261438, 0.00261438, 0.00261438],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00522876, 0.00522876, 0.00522876],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "26517504/44107200 [=================>............] - ETA: 5:54"
     ]
    }
   ],
   "source": [
    "model = EfficientNetB3(weights='imagenet', input_shape = (32,32,3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 3.8202 - accuracy: 0.2334 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 2.8257 - accuracy: 0.3374 - lr: 9.5000e-04\n",
      "Epoch 3/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 2.5206 - accuracy: 0.4048 - lr: 9.0250e-04\n",
      "Epoch 4/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 2.3187 - accuracy: 0.4443 - lr: 8.5737e-04\n",
      "Epoch 5/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 2.2180 - accuracy: 0.4810 - lr: 8.1451e-04\n",
      "Epoch 6/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 2.0682 - accuracy: 0.5151 - lr: 7.7378e-04\n",
      "Epoch 7/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.9362 - accuracy: 0.5610 - lr: 7.3509e-04\n",
      "Epoch 8/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.7413 - accuracy: 0.6294 - lr: 6.9834e-04\n",
      "Epoch 9/200\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 1.6907 - accuracy: 0.6396 - lr: 6.6342e-04\n",
      "Epoch 10/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.6530 - accuracy: 0.6455 - lr: 6.3025e-04\n",
      "Epoch 11/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.5674 - accuracy: 0.6626 - lr: 5.9874e-04\n",
      "Epoch 12/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.5132 - accuracy: 0.6943 - lr: 5.6880e-04\n",
      "Epoch 13/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.4833 - accuracy: 0.6934 - lr: 5.4036e-04\n",
      "Epoch 14/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.3698 - accuracy: 0.7241 - lr: 5.1334e-04\n",
      "Epoch 15/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.3080 - accuracy: 0.7466 - lr: 4.8767e-04\n",
      "Epoch 16/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.3368 - accuracy: 0.7246 - lr: 4.6329e-04\n",
      "Epoch 17/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.2615 - accuracy: 0.7534 - lr: 4.4013e-04\n",
      "Epoch 18/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.2730 - accuracy: 0.7402 - lr: 4.1812e-04\n",
      "Epoch 19/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.1742 - accuracy: 0.7671 - lr: 3.9721e-04\n",
      "Epoch 20/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.1708 - accuracy: 0.7720 - lr: 3.7735e-04\n",
      "Epoch 21/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.1179 - accuracy: 0.7837 - lr: 3.5849e-04\n",
      "Epoch 22/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.0735 - accuracy: 0.7998 - lr: 3.4056e-04\n",
      "Epoch 23/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.0504 - accuracy: 0.8047 - lr: 3.2353e-04\n",
      "Epoch 24/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.0187 - accuracy: 0.7944 - lr: 3.0736e-04\n",
      "Epoch 25/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.0048 - accuracy: 0.8174 - lr: 2.9199e-04\n",
      "Epoch 26/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.0071 - accuracy: 0.8037 - lr: 2.7739e-04\n",
      "Epoch 27/200\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.9531 - accuracy: 0.8374 - lr: 2.6352e-04\n",
      "Epoch 28/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.9174 - accuracy: 0.8364 - lr: 2.5034e-04\n",
      "Epoch 29/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.9419 - accuracy: 0.8179 - lr: 2.3783e-04\n",
      "Epoch 30/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.8964 - accuracy: 0.8330 - lr: 2.2594e-04\n",
      "Epoch 31/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.8969 - accuracy: 0.8350 - lr: 2.1464e-04\n",
      "Epoch 32/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.8566 - accuracy: 0.8491 - lr: 2.0391e-04\n",
      "Epoch 33/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.8588 - accuracy: 0.8496 - lr: 1.9371e-04\n",
      "Epoch 34/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.7936 - accuracy: 0.8682 - lr: 1.8403e-04\n",
      "Epoch 35/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.7982 - accuracy: 0.8667 - lr: 1.7482e-04\n",
      "Epoch 36/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.7657 - accuracy: 0.8809 - lr: 1.6608e-04\n",
      "Epoch 37/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.7756 - accuracy: 0.8657 - lr: 1.5778e-04\n",
      "Epoch 38/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.7543 - accuracy: 0.8662 - lr: 1.4989e-04\n",
      "Epoch 39/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.7267 - accuracy: 0.8760 - lr: 1.4240e-04\n",
      "Epoch 40/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.7034 - accuracy: 0.8823 - lr: 1.3528e-04\n",
      "Epoch 41/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6777 - accuracy: 0.8999 - lr: 1.2851e-04\n",
      "Epoch 42/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6942 - accuracy: 0.8896 - lr: 1.2209e-04\n",
      "Epoch 43/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6731 - accuracy: 0.9019 - lr: 1.1598e-04\n",
      "Epoch 44/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6459 - accuracy: 0.9009 - lr: 1.1018e-04\n",
      "Epoch 45/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6469 - accuracy: 0.9058 - lr: 1.0467e-04\n",
      "Epoch 46/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6658 - accuracy: 0.8901 - lr: 9.9440e-05\n",
      "Epoch 47/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6374 - accuracy: 0.8984 - lr: 9.4468e-05\n",
      "Epoch 48/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6255 - accuracy: 0.9062 - lr: 8.9745e-05\n",
      "Epoch 49/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6160 - accuracy: 0.9058 - lr: 8.5258e-05\n",
      "Epoch 50/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5979 - accuracy: 0.9141 - lr: 8.0995e-05\n",
      "Epoch 51/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5990 - accuracy: 0.9121 - lr: 7.6945e-05\n",
      "Epoch 52/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5652 - accuracy: 0.9238 - lr: 7.3098e-05\n",
      "Epoch 53/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5716 - accuracy: 0.9194 - lr: 6.9443e-05\n",
      "Epoch 54/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5776 - accuracy: 0.9243 - lr: 6.5971e-05\n",
      "Epoch 55/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5677 - accuracy: 0.9233 - lr: 6.2672e-05\n",
      "Epoch 56/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5421 - accuracy: 0.9336 - lr: 5.9539e-05\n",
      "Epoch 57/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5620 - accuracy: 0.9214 - lr: 5.6562e-05\n",
      "Epoch 58/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5372 - accuracy: 0.9297 - lr: 5.3734e-05\n",
      "Epoch 59/200\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.5379 - accuracy: 0.9331 - lr: 5.1047e-05\n",
      "Epoch 60/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5365 - accuracy: 0.9292 - lr: 4.8495e-05\n",
      "Epoch 61/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5380 - accuracy: 0.9316 - lr: 4.6070e-05\n",
      "Epoch 62/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4901 - accuracy: 0.9497 - lr: 4.3766e-05\n",
      "Epoch 63/200\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.5306 - accuracy: 0.9321 - lr: 4.1578e-05\n",
      "Epoch 64/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5347 - accuracy: 0.9326 - lr: 3.9499e-05\n",
      "Epoch 65/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5311 - accuracy: 0.9258 - lr: 3.7524e-05\n",
      "Epoch 66/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5087 - accuracy: 0.9395 - lr: 3.5648e-05\n",
      "Epoch 67/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5028 - accuracy: 0.9409 - lr: 3.3866e-05\n",
      "Epoch 68/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5020 - accuracy: 0.9360 - lr: 3.2172e-05\n",
      "Epoch 69/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4936 - accuracy: 0.9419 - lr: 3.0564e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4934 - accuracy: 0.9414 - lr: 2.9035e-05\n",
      "Epoch 71/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4856 - accuracy: 0.9468 - lr: 2.7584e-05\n",
      "Epoch 72/200\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.5008 - accuracy: 0.9419 - lr: 2.6205e-05\n",
      "Epoch 73/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4802 - accuracy: 0.9463 - lr: 2.4894e-05\n",
      "Epoch 74/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4968 - accuracy: 0.9424 - lr: 2.3650e-05\n",
      "Epoch 75/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4934 - accuracy: 0.9453 - lr: 2.2467e-05\n",
      "Epoch 76/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4882 - accuracy: 0.9409 - lr: 2.1344e-05\n",
      "Epoch 77/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4865 - accuracy: 0.9473 - lr: 2.0277e-05\n",
      "Epoch 78/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4705 - accuracy: 0.9497 - lr: 1.9263e-05\n",
      "Epoch 79/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4750 - accuracy: 0.9458 - lr: 1.8300e-05\n",
      "Epoch 80/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4479 - accuracy: 0.9575 - lr: 1.7385e-05\n",
      "Epoch 81/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4582 - accuracy: 0.9531 - lr: 1.6515e-05\n",
      "Epoch 82/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4801 - accuracy: 0.9473 - lr: 1.5690e-05\n",
      "Epoch 83/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4705 - accuracy: 0.9492 - lr: 1.4905e-05\n",
      "Epoch 84/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4775 - accuracy: 0.9409 - lr: 1.4160e-05\n",
      "Epoch 85/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4581 - accuracy: 0.9482 - lr: 1.3452e-05\n",
      "Epoch 86/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4542 - accuracy: 0.9561 - lr: 1.2779e-05\n",
      "Epoch 87/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4565 - accuracy: 0.9556 - lr: 1.2140e-05\n",
      "Epoch 88/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4474 - accuracy: 0.9556 - lr: 1.1533e-05\n",
      "Epoch 89/200\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4678 - accuracy: 0.9487 - lr: 1.0957e-05\n",
      "Epoch 90/200\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4608 - accuracy: 0.9526 - lr: 1.0409e-05\n",
      "Epoch 91/200\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4654 - accuracy: 0.9507 - lr: 9.8884e-06\n",
      "Epoch 92/200\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4610 - accuracy: 0.9517 - lr: 9.3939e-06\n",
      "Epoch 93/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4377 - accuracy: 0.9585 - lr: 8.9242e-06\n",
      "Epoch 94/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4581 - accuracy: 0.9492 - lr: 8.4780e-06\n",
      "Epoch 95/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4411 - accuracy: 0.9541 - lr: 8.0541e-06\n",
      "Epoch 96/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4469 - accuracy: 0.9561 - lr: 7.6514e-06\n",
      "Epoch 97/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4498 - accuracy: 0.9556 - lr: 7.2689e-06\n",
      "Epoch 98/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4563 - accuracy: 0.9536 - lr: 6.9054e-06\n",
      "Epoch 99/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4513 - accuracy: 0.9531 - lr: 6.5601e-06\n",
      "Epoch 100/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4620 - accuracy: 0.9453 - lr: 6.2321e-06\n",
      "Epoch 101/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4632 - accuracy: 0.9478 - lr: 5.9205e-06\n",
      "Epoch 102/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4576 - accuracy: 0.9482 - lr: 5.6245e-06\n",
      "Epoch 103/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4470 - accuracy: 0.9575 - lr: 5.3433e-06\n",
      "Epoch 104/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4355 - accuracy: 0.9565 - lr: 5.0761e-06\n",
      "Epoch 105/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4458 - accuracy: 0.9590 - lr: 4.8223e-06\n",
      "Epoch 106/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4642 - accuracy: 0.9438 - lr: 4.5812e-06\n",
      "Epoch 107/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4490 - accuracy: 0.9526 - lr: 4.3521e-06\n",
      "Epoch 108/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4494 - accuracy: 0.9526 - lr: 4.1345e-06\n",
      "Epoch 109/200\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4629 - accuracy: 0.9502 - lr: 3.9278e-06\n",
      "Epoch 110/200\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4357 - accuracy: 0.9600 - lr: 3.7314e-06\n",
      "Epoch 111/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4346 - accuracy: 0.9614 - lr: 3.5448e-06\n",
      "Epoch 112/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4461 - accuracy: 0.9546 - lr: 3.3676e-06\n",
      "Epoch 113/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4651 - accuracy: 0.9482 - lr: 3.1992e-06\n",
      "Epoch 114/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4584 - accuracy: 0.9468 - lr: 3.0393e-06\n",
      "Epoch 115/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4475 - accuracy: 0.9526 - lr: 2.8873e-06\n",
      "Epoch 116/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4566 - accuracy: 0.9517 - lr: 2.7429e-06\n",
      "Epoch 117/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4471 - accuracy: 0.9551 - lr: 2.6058e-06\n",
      "Epoch 118/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4465 - accuracy: 0.9497 - lr: 2.4755e-06\n",
      "Epoch 119/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4339 - accuracy: 0.9604 - lr: 2.3517e-06\n",
      "Epoch 120/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4337 - accuracy: 0.9565 - lr: 2.2341e-06\n",
      "Epoch 121/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4484 - accuracy: 0.9453 - lr: 2.1224e-06\n",
      "Epoch 122/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4497 - accuracy: 0.9517 - lr: 2.0163e-06\n",
      "Epoch 123/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4613 - accuracy: 0.9482 - lr: 1.9155e-06\n",
      "Epoch 124/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4554 - accuracy: 0.9473 - lr: 1.8197e-06\n",
      "Epoch 125/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4359 - accuracy: 0.9614 - lr: 1.7287e-06\n",
      "Epoch 126/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4472 - accuracy: 0.9487 - lr: 1.6423e-06\n",
      "Epoch 127/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4375 - accuracy: 0.9609 - lr: 1.5602e-06\n",
      "Epoch 128/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4298 - accuracy: 0.9595 - lr: 1.4822e-06\n",
      "Epoch 129/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4498 - accuracy: 0.9590 - lr: 1.4081e-06\n",
      "Epoch 130/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4312 - accuracy: 0.9565 - lr: 1.3377e-06\n",
      "Epoch 131/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4490 - accuracy: 0.9536 - lr: 1.2708e-06\n",
      "Epoch 132/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4283 - accuracy: 0.9585 - lr: 1.2072e-06\n",
      "Epoch 133/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4299 - accuracy: 0.9561 - lr: 1.1469e-06\n",
      "Epoch 134/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4408 - accuracy: 0.9541 - lr: 1.0895e-06\n",
      "Epoch 135/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4269 - accuracy: 0.9634 - lr: 1.0351e-06\n",
      "Epoch 136/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4400 - accuracy: 0.9575 - lr: 9.8330e-07\n",
      "Epoch 137/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4435 - accuracy: 0.9551 - lr: 9.3414e-07\n",
      "Epoch 138/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4353 - accuracy: 0.9561 - lr: 8.8743e-07\n",
      "Epoch 139/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4449 - accuracy: 0.9541 - lr: 8.4306e-07\n",
      "Epoch 140/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4207 - accuracy: 0.9580 - lr: 8.0091e-07\n",
      "Epoch 141/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4601 - accuracy: 0.9478 - lr: 7.6086e-07\n",
      "Epoch 142/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4327 - accuracy: 0.9580 - lr: 7.2282e-07\n",
      "Epoch 143/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4520 - accuracy: 0.9536 - lr: 6.8668e-07\n",
      "Epoch 144/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4359 - accuracy: 0.9624 - lr: 6.5234e-07\n",
      "Epoch 145/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4351 - accuracy: 0.9556 - lr: 6.1973e-07\n",
      "Epoch 146/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4452 - accuracy: 0.9580 - lr: 5.8874e-07\n",
      "Epoch 147/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4246 - accuracy: 0.9644 - lr: 5.5930e-07\n",
      "Epoch 148/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4413 - accuracy: 0.9536 - lr: 5.3134e-07\n",
      "Epoch 149/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4205 - accuracy: 0.9663 - lr: 5.0477e-07\n",
      "Epoch 150/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4195 - accuracy: 0.9648 - lr: 4.7953e-07\n",
      "Epoch 151/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4404 - accuracy: 0.9536 - lr: 4.5555e-07\n",
      "Epoch 152/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4492 - accuracy: 0.9492 - lr: 4.3278e-07\n",
      "Epoch 153/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4373 - accuracy: 0.9595 - lr: 4.1114e-07\n",
      "Epoch 154/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4249 - accuracy: 0.9575 - lr: 3.9058e-07\n",
      "Epoch 155/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4417 - accuracy: 0.9521 - lr: 3.7105e-07\n",
      "Epoch 156/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4355 - accuracy: 0.9541 - lr: 3.5250e-07\n",
      "Epoch 157/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4580 - accuracy: 0.9458 - lr: 3.3487e-07\n",
      "Epoch 158/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4385 - accuracy: 0.9536 - lr: 3.1813e-07\n",
      "Epoch 159/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4455 - accuracy: 0.9580 - lr: 3.0222e-07\n",
      "Epoch 160/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4369 - accuracy: 0.9609 - lr: 2.8711e-07\n",
      "Epoch 161/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4529 - accuracy: 0.9502 - lr: 2.7276e-07\n",
      "Epoch 162/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4551 - accuracy: 0.9541 - lr: 2.5912e-07\n",
      "Epoch 163/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4625 - accuracy: 0.9443 - lr: 2.4616e-07\n",
      "Epoch 164/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4382 - accuracy: 0.9585 - lr: 2.3386e-07\n",
      "Epoch 165/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4287 - accuracy: 0.9653 - lr: 2.2216e-07\n",
      "Epoch 166/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4403 - accuracy: 0.9526 - lr: 2.1105e-07\n",
      "Epoch 167/200\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4341 - accuracy: 0.9536 - lr: 2.0050e-07\n",
      "Epoch 168/200\n",
      "104/128 [=======================>......] - ETA: 0s - loss: 0.4320 - accuracy: 0.9591"
     ]
    }
   ],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "\n",
    "# 이미지 증식 사용\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  \n",
    "    zoom_range = 0.1, \n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "   # brightness_range=[0.8,1.2] #이걸조절하니까 다 1로예측함 ㅠㅠ\n",
    ")\n",
    "\n",
    "model = create_cnn_model()\n",
    "\n",
    "#model.fit(x_train, y_train, epochs=50)\n",
    "\n",
    "history = model.fit(\n",
    "  datagen.flow(x_train, y_train, batch_size=16),\n",
    "  epochs=200, \n",
    "  steps_per_epoch = x_train.shape[0]//16,\n",
    "  callbacks=[annealer], \n",
    "  verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2049</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2051</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2052</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2053</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2054</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2055</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2057</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2058</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2060</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2062</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2064</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2068</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2069</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2070</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2072</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2073</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2074</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2077</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2078</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2080</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2083</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2086</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2087</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2088</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2091</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2092</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2096</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  digit\n",
       "0   2049      6\n",
       "1   2050      5\n",
       "2   2051      6\n",
       "3   2052      8\n",
       "4   2053      3\n",
       "5   2054      8\n",
       "6   2055      5\n",
       "7   2056      3\n",
       "8   2057      1\n",
       "9   2058      4\n",
       "10  2059      1\n",
       "11  2060      6\n",
       "12  2061      1\n",
       "13  2062      5\n",
       "14  2063      1\n",
       "15  2064      5\n",
       "16  2065      1\n",
       "17  2066      6\n",
       "18  2067      1\n",
       "19  2068      4\n",
       "20  2069      6\n",
       "21  2070      9\n",
       "22  2071      1\n",
       "23  2072      5\n",
       "24  2073      5\n",
       "25  2074      5\n",
       "26  2075      0\n",
       "27  2076      1\n",
       "28  2077      9\n",
       "29  2078      8\n",
       "30  2079      1\n",
       "31  2080      8\n",
       "32  2081      1\n",
       "33  2082      0\n",
       "34  2083      6\n",
       "35  2084      1\n",
       "36  2085      1\n",
       "37  2086      5\n",
       "38  2087      6\n",
       "39  2088      4\n",
       "40  2089      1\n",
       "41  2090      1\n",
       "42  2091      8\n",
       "43  2092      5\n",
       "44  2093      1\n",
       "45  2094      0\n",
       "46  2095      1\n",
       "47  2096      8\n",
       "48  2097      1\n",
       "49  2098      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test/255\n",
    "\n",
    "submission = pd.read_csv('data/submission.csv')\n",
    "submission['digit'] = np.argmax(model.predict(x_test), axis=1)\n",
    "submission.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('epoch200_parm수정2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
