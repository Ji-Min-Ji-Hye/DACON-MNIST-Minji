{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers # L2규제\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # data augmentation\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler # callbacks 설정\n",
    "\n",
    "from tqdm.notebook import tqdm # 모델학습 진행 시간 파악\n",
    "import random # random seed를 뽑을때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#gpu사용\n",
    "config= tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 13\n",
    "img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
    "digit = train.loc[idx, 'digit']\n",
    "letter = train.loc[idx, 'letter']\n",
    "\n",
    "plt.title('Index: %i, Digit: %s, Letter: %s'%(idx, digit, letter))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(['id', 'digit', 'letter'], axis=1).values\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_edit=x_train\n",
    "x_train = x_train/255\n",
    "\n",
    "y = train['digit']\n",
    "y_train = np.zeros((len(y), len(y.unique())))\n",
    "for i, digit in enumerate(y):\n",
    "    y_train[i, digit] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold=140 #임계값\n",
    "for i in range(0,2048):\n",
    "    for j in range(0,28):\n",
    "        for k in range(0,28):\n",
    "            if(x_edit[i][j][k][0]<=threshold):\n",
    "                x_edit[i][j][k][0]=0\n",
    "            else:\n",
    "                x_edit[i][j][k][0]=255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "[[0.00784314]\n",
      " [0.        ]\n",
      " [0.02352941]\n",
      " [0.07058824]\n",
      " [0.07843137]\n",
      " [0.23921569]\n",
      " [0.26666667]\n",
      " [0.43921569]\n",
      " [0.83529412]\n",
      " [0.89803922]\n",
      " [0.92941176]\n",
      " [0.92156863]\n",
      " [0.91764706]\n",
      " [0.92156863]\n",
      " [0.88627451]\n",
      " [0.88627451]\n",
      " [0.94117647]\n",
      " [0.95294118]\n",
      " [0.93333333]\n",
      " [0.70980392]\n",
      " [0.21960784]\n",
      " [0.        ]\n",
      " [0.01568627]\n",
      " [0.00784314]\n",
      " [0.01176471]\n",
      " [0.        ]\n",
      " [0.00392157]\n",
      " [0.00784314]]\n"
     ]
    }
   ],
   "source": [
    "#결과확인\n",
    "print(x_edit[2046][7])\n",
    "print(x_train[2046][7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = np.repeat(x_train, 3, axis=1)\n",
    "x_train2 = np.repeat(x_train1, 3, axis=2)\n",
    "x_edit1=np.repeat(x_edit, 3, axis=1)\n",
    "x_edit2=np.repeat(x_edit1, 3, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 84, 84, 1) (2048, 84, 84, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train2.shape, x_edit2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    inputs = Input(shape = (84,84,1))\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(inputs)\n",
    "    conv = tf.keras.layers.Conv2D(64, kernel_size=5, strides=1, padding='same', activation='relu')(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(64, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2, 2))(conv)\n",
    "    \n",
    "    do=tf.keras.layers.Dropout(0.4)(pool)\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(do)\n",
    "    conv = tf.keras.layers.Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu',kernel_regularizer = regularizers.l2(0.001))(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu',kernel_regularizer = regularizers.l2(0.001))(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "    do=tf.keras.layers.Dropout(0.4)(pool)\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(do)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu',kernel_regularizer = regularizers.l2(0.001))(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu',kernel_regularizer = regularizers.l2(0.001))(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "    flatten = tf.keras.layers.Flatten()(pool)\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(flatten)\n",
    "    dense = tf.keras.layers.Dense(1000, activation='relu')(bn)\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(dense)\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(bn)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 84, 84, 1)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 84, 84, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 84, 84, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 84, 84, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 84, 84, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 42, 42, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 42, 42, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 42, 42, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 42, 42, 128)       65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 21, 21, 256)       131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 21, 21, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 21, 21, 256)       262400    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 25600)             102400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              25601000  \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 26,402,406\n",
      "Trainable params: 26,347,924\n",
      "Non-trainable params: 54,482\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_cnn_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 3.8072 - accuracy: 0.3032\n",
      "Epoch 2/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 2.6466 - accuracy: 0.3818\n",
      "Epoch 3/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 2.4681 - accuracy: 0.4038\n",
      "Epoch 4/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 2.2732 - accuracy: 0.4551\n",
      "Epoch 5/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 2.2523 - accuracy: 0.4521\n",
      "Epoch 6/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 2.1802 - accuracy: 0.4521\n",
      "Epoch 7/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 2.1223 - accuracy: 0.4756\n",
      "Epoch 8/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 2.0259 - accuracy: 0.5054\n",
      "Epoch 9/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 1.9499 - accuracy: 0.5093\n",
      "Epoch 10/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 1.8773 - accuracy: 0.5400\n",
      "Epoch 11/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 1.8896 - accuracy: 0.5396\n",
      "Epoch 12/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 1.8289 - accuracy: 0.5410\n",
      "Epoch 13/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 1.7599 - accuracy: 0.5625 0s - loss: 1\n",
      "Epoch 14/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 1.7377 - accuracy: 0.5713\n",
      "Epoch 15/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 1.6671 - accuracy: 0.5771\n",
      "Epoch 16/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 1.6243 - accuracy: 0.5928\n",
      "Epoch 17/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 1.5973 - accuracy: 0.5933\n",
      "Epoch 18/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 1.5632 - accuracy: 0.6001\n",
      "Epoch 19/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 1.5500 - accuracy: 0.6196\n",
      "Epoch 20/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 1.5469 - accuracy: 0.6050\n",
      "Epoch 21/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 1.5137 - accuracy: 0.6094\n",
      "Epoch 22/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 1.4428 - accuracy: 0.6309\n",
      "Epoch 23/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 1.4325 - accuracy: 0.6211\n",
      "Epoch 24/100\n",
      "128/128 [==============================] - 3s 23ms/step - loss: 1.4154 - accuracy: 0.6274\n",
      "Epoch 25/100\n",
      "128/128 [==============================] - 3s 22ms/step - loss: 1.3932 - accuracy: 0.6411\n",
      "Epoch 26/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.3855 - accuracy: 0.6377\n",
      "Epoch 27/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.3161 - accuracy: 0.6445\n",
      "Epoch 28/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.2956 - accuracy: 0.6558\n",
      "Epoch 29/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.2843 - accuracy: 0.6670\n",
      "Epoch 30/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.2185 - accuracy: 0.6860\n",
      "Epoch 31/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.2093 - accuracy: 0.6851\n",
      "Epoch 32/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.1623 - accuracy: 0.6885\n",
      "Epoch 33/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.1738 - accuracy: 0.6924\n",
      "Epoch 34/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.1470 - accuracy: 0.7061\n",
      "Epoch 35/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.1200 - accuracy: 0.7046\n",
      "Epoch 36/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.1082 - accuracy: 0.7153\n",
      "Epoch 37/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.0793 - accuracy: 0.7124\n",
      "Epoch 38/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.0769 - accuracy: 0.7236\n",
      "Epoch 39/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.0168 - accuracy: 0.7466\n",
      "Epoch 40/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 1.0125 - accuracy: 0.7456\n",
      "Epoch 41/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.9538 - accuracy: 0.7593\n",
      "Epoch 42/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.9901 - accuracy: 0.7534\n",
      "Epoch 43/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.9681 - accuracy: 0.7471\n",
      "Epoch 44/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.9298 - accuracy: 0.7749\n",
      "Epoch 45/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.9393 - accuracy: 0.7588\n",
      "Epoch 46/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.9279 - accuracy: 0.7686\n",
      "Epoch 47/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.8743 - accuracy: 0.7744\n",
      "Epoch 48/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.9028 - accuracy: 0.7856\n",
      "Epoch 49/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.8755 - accuracy: 0.7769\n",
      "Epoch 50/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.8655 - accuracy: 0.7798\n",
      "Epoch 51/100\n",
      "128/128 [==============================] - 3s 21ms/step - loss: 0.8159 - accuracy: 0.8008\n",
      "Epoch 52/100\n",
      "128/128 [==============================] - 3s 21ms/step - loss: 0.8435 - accuracy: 0.7871\n",
      "Epoch 53/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.8038 - accuracy: 0.8062\n",
      "Epoch 54/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.7993 - accuracy: 0.8062\n",
      "Epoch 55/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.7916 - accuracy: 0.8130\n",
      "Epoch 56/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.7851 - accuracy: 0.8081\n",
      "Epoch 57/100\n",
      "128/128 [==============================] - 3s 21ms/step - loss: 0.7783 - accuracy: 0.8120\n",
      "Epoch 58/100\n",
      "128/128 [==============================] - 3s 21ms/step - loss: 0.7642 - accuracy: 0.8115\n",
      "Epoch 59/100\n",
      "128/128 [==============================] - 3s 21ms/step - loss: 0.7661 - accuracy: 0.8154\n",
      "Epoch 60/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.7348 - accuracy: 0.8291\n",
      "Epoch 61/100\n",
      "128/128 [==============================] - 3s 21ms/step - loss: 0.7162 - accuracy: 0.8374\n",
      "Epoch 62/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.7310 - accuracy: 0.8306\n",
      "Epoch 63/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.7196 - accuracy: 0.8320\n",
      "Epoch 64/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.7055 - accuracy: 0.8433\n",
      "Epoch 65/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.7146 - accuracy: 0.8374\n",
      "Epoch 66/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.7122 - accuracy: 0.8340\n",
      "Epoch 67/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6851 - accuracy: 0.8525\n",
      "Epoch 68/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6907 - accuracy: 0.8457\n",
      "Epoch 69/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6832 - accuracy: 0.8511\n",
      "Epoch 70/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6857 - accuracy: 0.8418\n",
      "Epoch 71/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6585 - accuracy: 0.8521\n",
      "Epoch 72/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6663 - accuracy: 0.8530\n",
      "Epoch 73/100\n",
      "128/128 [==============================] - 3s 21ms/step - loss: 0.6417 - accuracy: 0.8633\n",
      "Epoch 74/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6568 - accuracy: 0.8672\n",
      "Epoch 75/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6509 - accuracy: 0.8511\n",
      "Epoch 76/100\n",
      "128/128 [==============================] - 3s 21ms/step - loss: 0.6345 - accuracy: 0.8579\n",
      "Epoch 77/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6526 - accuracy: 0.8555\n",
      "Epoch 78/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6542 - accuracy: 0.8447\n",
      "Epoch 79/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6460 - accuracy: 0.8638\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6280 - accuracy: 0.8638\n",
      "Epoch 81/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6414 - accuracy: 0.8506\n",
      "Epoch 82/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6309 - accuracy: 0.8633\n",
      "Epoch 83/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6037 - accuracy: 0.8779\n",
      "Epoch 84/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6242 - accuracy: 0.8667\n",
      "Epoch 85/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6011 - accuracy: 0.8770\n",
      "Epoch 86/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6166 - accuracy: 0.8706\n",
      "Epoch 87/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.5951 - accuracy: 0.8667\n",
      "Epoch 88/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.5809 - accuracy: 0.8774\n",
      "Epoch 89/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6146 - accuracy: 0.8633\n",
      "Epoch 90/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6056 - accuracy: 0.8774\n",
      "Epoch 91/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.5921 - accuracy: 0.8765\n",
      "Epoch 92/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6089 - accuracy: 0.8745\n",
      "Epoch 93/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.5908 - accuracy: 0.8735\n",
      "Epoch 94/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.5853 - accuracy: 0.8857\n",
      "Epoch 95/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.5868 - accuracy: 0.8784\n",
      "Epoch 96/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.5952 - accuracy: 0.8774\n",
      "Epoch 97/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6208 - accuracy: 0.8657\n",
      "Epoch 98/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.5916 - accuracy: 0.8784\n",
      "Epoch 99/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.5928 - accuracy: 0.8823\n",
      "Epoch 100/100\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.5797 - accuracy: 0.8794\n"
     ]
    }
   ],
   "source": [
    "# 초반 이미지 학습\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "\n",
    "# 이미지 증식 사용\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  \n",
    "    zoom_range = 0.1, \n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1)\n",
    "\n",
    "model = create_cnn_model()\n",
    "epochs=100\n",
    "\n",
    "#model.fit(x_train, y_train, epochs=50)\n",
    "history = model.fit(\n",
    "  datagen.flow(x_edit2, y_train, batch_size=16),\n",
    "  epochs=epochs, \n",
    "  steps_per_epoch = x_edit2.shape[0]//16,\n",
    "  callbacks=[annealer], \n",
    "  verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      " 1/64 [..............................] - ETA: 0s - loss: 2.9570 - accuracy: 0.2812WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 0.0204s). Check your callbacks.\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 1.4061 - accuracy: 0.6055\n",
      "Epoch 2/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.9861 - accuracy: 0.7378\n",
      "Epoch 3/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.8167 - accuracy: 0.8008\n",
      "Epoch 4/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.6867 - accuracy: 0.8467\n",
      "Epoch 5/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.6496 - accuracy: 0.8481\n",
      "Epoch 6/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.5858 - accuracy: 0.8696\n",
      "Epoch 7/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.5331 - accuracy: 0.8877\n",
      "Epoch 8/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.4800 - accuracy: 0.9087\n",
      "Epoch 9/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.4749 - accuracy: 0.9043\n",
      "Epoch 10/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.4499 - accuracy: 0.9067\n",
      "Epoch 11/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.4262 - accuracy: 0.9102\n",
      "Epoch 12/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3900 - accuracy: 0.9336\n",
      "Epoch 13/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3784 - accuracy: 0.9302\n",
      "Epoch 14/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3520 - accuracy: 0.9395\n",
      "Epoch 15/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3255 - accuracy: 0.9463\n",
      "Epoch 16/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3273 - accuracy: 0.9448\n",
      "Epoch 17/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3046 - accuracy: 0.9521\n",
      "Epoch 18/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2783 - accuracy: 0.9609\n",
      "Epoch 19/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2725 - accuracy: 0.9609\n",
      "Epoch 20/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2750 - accuracy: 0.9541\n",
      "Epoch 21/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2753 - accuracy: 0.9565\n",
      "Epoch 22/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2429 - accuracy: 0.9634\n",
      "Epoch 23/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2408 - accuracy: 0.9653\n",
      "Epoch 24/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2323 - accuracy: 0.9683\n",
      "Epoch 25/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2278 - accuracy: 0.9673\n",
      "Epoch 26/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2278 - accuracy: 0.9688\n",
      "Epoch 27/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1945 - accuracy: 0.9800\n",
      "Epoch 28/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2007 - accuracy: 0.9731\n",
      "Epoch 29/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1921 - accuracy: 0.9805\n",
      "Epoch 30/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1870 - accuracy: 0.9790\n",
      "Epoch 31/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1898 - accuracy: 0.9780\n",
      "Epoch 32/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1773 - accuracy: 0.9805\n",
      "Epoch 33/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1757 - accuracy: 0.9800\n",
      "Epoch 34/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1632 - accuracy: 0.9844 0s - loss: 0.1636 - accuracy: 0.98\n",
      "Epoch 35/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1650 - accuracy: 0.9824\n",
      "Epoch 36/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1590 - accuracy: 0.9858\n",
      "Epoch 37/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1532 - accuracy: 0.9858\n",
      "Epoch 38/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1524 - accuracy: 0.9873\n",
      "Epoch 39/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1511 - accuracy: 0.9873\n",
      "Epoch 40/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1453 - accuracy: 0.9883\n",
      "Epoch 41/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1542 - accuracy: 0.9814\n",
      "Epoch 42/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1415 - accuracy: 0.9893\n",
      "Epoch 43/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1372 - accuracy: 0.9893\n",
      "Epoch 44/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1454 - accuracy: 0.9839\n",
      "Epoch 45/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1327 - accuracy: 0.9897\n",
      "Epoch 46/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1246 - accuracy: 0.9927\n",
      "Epoch 47/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1292 - accuracy: 0.9907\n",
      "Epoch 48/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1280 - accuracy: 0.9897\n",
      "Epoch 49/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1278 - accuracy: 0.9893\n",
      "Epoch 50/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1167 - accuracy: 0.9907\n",
      "Epoch 51/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1180 - accuracy: 0.9932\n",
      "Epoch 52/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1171 - accuracy: 0.9917\n",
      "Epoch 53/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1216 - accuracy: 0.9893\n",
      "Epoch 54/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1081 - accuracy: 0.9932\n",
      "Epoch 55/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1129 - accuracy: 0.9946\n",
      "Epoch 56/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1074 - accuracy: 0.9937\n",
      "Epoch 57/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.1081 - accuracy: 0.9946\n",
      "Epoch 58/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1100 - accuracy: 0.9917\n",
      "Epoch 59/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1053 - accuracy: 0.9937\n",
      "Epoch 60/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1090 - accuracy: 0.9927\n",
      "Epoch 61/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1059 - accuracy: 0.9922\n",
      "Epoch 62/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1108 - accuracy: 0.9922\n",
      "Epoch 63/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1060 - accuracy: 0.9897\n",
      "Epoch 64/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1052 - accuracy: 0.9941\n",
      "Epoch 65/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1011 - accuracy: 0.9941\n",
      "Epoch 66/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0996 - accuracy: 0.9941\n",
      "Epoch 67/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0961 - accuracy: 0.9937\n",
      "Epoch 68/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1043 - accuracy: 0.9917\n",
      "Epoch 69/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0982 - accuracy: 0.9951\n",
      "Epoch 70/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0990 - accuracy: 0.9937\n",
      "Epoch 71/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0938 - accuracy: 0.9976\n",
      "Epoch 72/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0927 - accuracy: 0.9966\n",
      "Epoch 73/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0959 - accuracy: 0.9946\n",
      "Epoch 74/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0915 - accuracy: 0.9966\n",
      "Epoch 75/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0928 - accuracy: 0.9971\n",
      "Epoch 76/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0927 - accuracy: 0.9956\n",
      "Epoch 77/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0904 - accuracy: 0.9966\n",
      "Epoch 78/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0949 - accuracy: 0.9951\n",
      "Epoch 79/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0912 - accuracy: 0.9956\n",
      "Epoch 80/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0894 - accuracy: 0.9976\n",
      "Epoch 1/80\n",
      " 1/64 [..............................] - ETA: 0s - loss: 0.0776 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0132s vs `on_train_batch_end` time: 0.0200s). Check your callbacks.\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 1.1303 - accuracy: 0.7324\n",
      "Epoch 2/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 1.1384 - accuracy: 0.7422\n",
      "Epoch 3/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.8553 - accuracy: 0.8154\n",
      "Epoch 4/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.6731 - accuracy: 0.8604\n",
      "Epoch 5/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.5449 - accuracy: 0.8867\n",
      "Epoch 6/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.5031 - accuracy: 0.9014\n",
      "Epoch 7/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.4438 - accuracy: 0.9131\n",
      "Epoch 8/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3902 - accuracy: 0.9268\n",
      "Epoch 9/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3742 - accuracy: 0.9297\n",
      "Epoch 10/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3420 - accuracy: 0.9331\n",
      "Epoch 11/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3130 - accuracy: 0.9399\n",
      "Epoch 12/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2807 - accuracy: 0.9487\n",
      "Epoch 13/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2729 - accuracy: 0.9551\n",
      "Epoch 14/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2808 - accuracy: 0.9512\n",
      "Epoch 15/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2352 - accuracy: 0.9648\n",
      "Epoch 16/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2391 - accuracy: 0.9604\n",
      "Epoch 17/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2164 - accuracy: 0.9600\n",
      "Epoch 18/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2240 - accuracy: 0.9580\n",
      "Epoch 19/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2092 - accuracy: 0.9653\n",
      "Epoch 20/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1903 - accuracy: 0.9688\n",
      "Epoch 21/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1756 - accuracy: 0.9731\n",
      "Epoch 22/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1621 - accuracy: 0.9795\n",
      "Epoch 23/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1644 - accuracy: 0.9746\n",
      "Epoch 24/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1472 - accuracy: 0.9819\n",
      "Epoch 25/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1400 - accuracy: 0.9800\n",
      "Epoch 26/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1282 - accuracy: 0.9873\n",
      "Epoch 27/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1331 - accuracy: 0.9844\n",
      "Epoch 28/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1333 - accuracy: 0.9805\n",
      "Epoch 29/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1310 - accuracy: 0.9800\n",
      "Epoch 30/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1255 - accuracy: 0.9844\n",
      "Epoch 31/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1247 - accuracy: 0.9795\n",
      "Epoch 32/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1219 - accuracy: 0.9810\n",
      "Epoch 33/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1123 - accuracy: 0.9902\n",
      "Epoch 34/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1074 - accuracy: 0.9873\n",
      "Epoch 35/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1045 - accuracy: 0.9849\n",
      "Epoch 36/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0917 - accuracy: 0.9917\n",
      "Epoch 37/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0952 - accuracy: 0.9902\n",
      "Epoch 38/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0905 - accuracy: 0.9912\n",
      "Epoch 39/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0891 - accuracy: 0.9907\n",
      "Epoch 40/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0864 - accuracy: 0.9932\n",
      "Epoch 41/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0908 - accuracy: 0.9897\n",
      "Epoch 42/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0811 - accuracy: 0.9912\n",
      "Epoch 43/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0836 - accuracy: 0.9907\n",
      "Epoch 44/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0833 - accuracy: 0.9907\n",
      "Epoch 45/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0790 - accuracy: 0.9932\n",
      "Epoch 46/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0790 - accuracy: 0.9922\n",
      "Epoch 47/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0851 - accuracy: 0.9912\n",
      "Epoch 48/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0798 - accuracy: 0.9937\n",
      "Epoch 49/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0710 - accuracy: 0.9932\n",
      "Epoch 50/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0708 - accuracy: 0.9937\n",
      "Epoch 51/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0662 - accuracy: 0.9956\n",
      "Epoch 52/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0748 - accuracy: 0.9922\n",
      "Epoch 53/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0734 - accuracy: 0.9932\n",
      "Epoch 54/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0700 - accuracy: 0.9937\n",
      "Epoch 55/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0685 - accuracy: 0.9937\n",
      "Epoch 56/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0626 - accuracy: 0.9941\n",
      "Epoch 57/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0588 - accuracy: 0.9951\n",
      "Epoch 58/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0652 - accuracy: 0.9902\n",
      "Epoch 59/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0607 - accuracy: 0.9946\n",
      "Epoch 60/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0589 - accuracy: 0.9941\n",
      "Epoch 61/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0591 - accuracy: 0.9956\n",
      "Epoch 62/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0590 - accuracy: 0.9956\n",
      "Epoch 63/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0596 - accuracy: 0.9932\n",
      "Epoch 64/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0590 - accuracy: 0.9951\n",
      "Epoch 65/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0550 - accuracy: 0.9961\n",
      "Epoch 66/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0584 - accuracy: 0.9956\n",
      "Epoch 67/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0522 - accuracy: 0.9980\n",
      "Epoch 68/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0573 - accuracy: 0.9941\n",
      "Epoch 69/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0511 - accuracy: 0.9961\n",
      "Epoch 70/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0565 - accuracy: 0.9946\n",
      "Epoch 71/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0520 - accuracy: 0.9956\n",
      "Epoch 72/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0550 - accuracy: 0.9971\n",
      "Epoch 73/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0569 - accuracy: 0.9937\n",
      "Epoch 74/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0552 - accuracy: 0.9956\n",
      "Epoch 75/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0546 - accuracy: 0.9951\n",
      "Epoch 76/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0510 - accuracy: 0.9971\n",
      "Epoch 77/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0479 - accuracy: 0.9971\n",
      "Epoch 78/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0500 - accuracy: 0.9985\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0512 - accuracy: 0.9956\n",
      "Epoch 80/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0486 - accuracy: 0.9971\n",
      "Epoch 1/80\n",
      " 1/64 [..............................] - ETA: 0s - loss: 0.0418 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.0224s). Check your callbacks.\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.7882 - accuracy: 0.8105\n",
      "Epoch 2/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.9003 - accuracy: 0.8145\n",
      "Epoch 3/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.6259 - accuracy: 0.8711\n",
      "Epoch 4/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.5779 - accuracy: 0.8906\n",
      "Epoch 5/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.4920 - accuracy: 0.9087\n",
      "Epoch 6/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3997 - accuracy: 0.9409\n",
      "Epoch 7/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3634 - accuracy: 0.9355\n",
      "Epoch 8/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3223 - accuracy: 0.9468\n",
      "Epoch 9/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3273 - accuracy: 0.9390\n",
      "Epoch 10/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3094 - accuracy: 0.9438\n",
      "Epoch 11/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2667 - accuracy: 0.9541\n",
      "Epoch 12/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2403 - accuracy: 0.9609\n",
      "Epoch 13/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2264 - accuracy: 0.9644\n",
      "Epoch 14/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2056 - accuracy: 0.9683\n",
      "Epoch 15/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1955 - accuracy: 0.9731\n",
      "Epoch 16/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1976 - accuracy: 0.9688\n",
      "Epoch 17/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1786 - accuracy: 0.9722\n",
      "Epoch 18/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1956 - accuracy: 0.9658\n",
      "Epoch 19/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1762 - accuracy: 0.9727\n",
      "Epoch 20/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1467 - accuracy: 0.9824\n",
      "Epoch 21/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1603 - accuracy: 0.9736\n",
      "Epoch 22/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1463 - accuracy: 0.9810\n",
      "Epoch 23/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1378 - accuracy: 0.9839\n",
      "Epoch 24/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1281 - accuracy: 0.9814\n",
      "Epoch 25/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1233 - accuracy: 0.9844\n",
      "Epoch 26/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1232 - accuracy: 0.9814\n",
      "Epoch 27/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1235 - accuracy: 0.9814\n",
      "Epoch 28/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1116 - accuracy: 0.9849\n",
      "Epoch 29/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1237 - accuracy: 0.9834\n",
      "Epoch 30/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.1019 - accuracy: 0.9883\n",
      "Epoch 31/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1075 - accuracy: 0.9878\n",
      "Epoch 32/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1728 - accuracy: 0.9639\n",
      "Epoch 33/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1190 - accuracy: 0.9849\n",
      "Epoch 34/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1277 - accuracy: 0.9834\n",
      "Epoch 35/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1095 - accuracy: 0.9883\n",
      "Epoch 36/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1114 - accuracy: 0.9883\n",
      "Epoch 37/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.1109 - accuracy: 0.9873\n",
      "Epoch 38/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1055 - accuracy: 0.9912\n",
      "Epoch 39/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1128 - accuracy: 0.9858\n",
      "Epoch 40/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0994 - accuracy: 0.9893\n",
      "Epoch 41/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0939 - accuracy: 0.9907\n",
      "Epoch 42/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0926 - accuracy: 0.9917\n",
      "Epoch 43/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0944 - accuracy: 0.9912\n",
      "Epoch 44/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0895 - accuracy: 0.9922\n",
      "Epoch 45/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0921 - accuracy: 0.9902\n",
      "Epoch 46/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0828 - accuracy: 0.9941\n",
      "Epoch 47/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0819 - accuracy: 0.9941\n",
      "Epoch 48/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0804 - accuracy: 0.9927\n",
      "Epoch 49/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0725 - accuracy: 0.9956\n",
      "Epoch 50/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0835 - accuracy: 0.9912\n",
      "Epoch 51/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0812 - accuracy: 0.9937\n",
      "Epoch 52/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0740 - accuracy: 0.9956\n",
      "Epoch 53/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0762 - accuracy: 0.9932\n",
      "Epoch 54/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0738 - accuracy: 0.9946\n",
      "Epoch 55/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0758 - accuracy: 0.9932\n",
      "Epoch 56/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0759 - accuracy: 0.9922\n",
      "Epoch 57/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0706 - accuracy: 0.9932\n",
      "Epoch 58/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0738 - accuracy: 0.9927\n",
      "Epoch 59/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0661 - accuracy: 0.9951\n",
      "Epoch 60/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0687 - accuracy: 0.9951\n",
      "Epoch 61/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0623 - accuracy: 0.9951\n",
      "Epoch 62/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0712 - accuracy: 0.9927\n",
      "Epoch 63/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0623 - accuracy: 0.9961\n",
      "Epoch 64/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0650 - accuracy: 0.9946\n",
      "Epoch 65/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0649 - accuracy: 0.9951\n",
      "Epoch 66/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0694 - accuracy: 0.9937\n",
      "Epoch 67/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0667 - accuracy: 0.9932\n",
      "Epoch 68/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0663 - accuracy: 0.9937\n",
      "Epoch 69/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0644 - accuracy: 0.9951\n",
      "Epoch 70/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0643 - accuracy: 0.9941\n",
      "Epoch 71/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0628 - accuracy: 0.9951\n",
      "Epoch 72/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0628 - accuracy: 0.9937\n",
      "Epoch 73/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0628 - accuracy: 0.9961\n",
      "Epoch 74/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0646 - accuracy: 0.9932\n",
      "Epoch 75/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0600 - accuracy: 0.9961\n",
      "Epoch 76/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0602 - accuracy: 0.9951\n",
      "Epoch 77/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0581 - accuracy: 0.9980\n",
      "Epoch 78/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0598 - accuracy: 0.9961\n",
      "Epoch 79/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0555 - accuracy: 0.9976\n",
      "Epoch 80/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0561 - accuracy: 0.9961\n",
      "Epoch 1/80\n",
      " 1/64 [..............................] - ETA: 0s - loss: 0.0506 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 0.0213s). Check your callbacks.\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.5374 - accuracy: 0.8740\n",
      "Epoch 2/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.6929 - accuracy: 0.8633\n",
      "Epoch 3/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.5669 - accuracy: 0.9014\n",
      "Epoch 4/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.4697 - accuracy: 0.9248\n",
      "Epoch 5/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.4220 - accuracy: 0.9297\n",
      "Epoch 6/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3567 - accuracy: 0.9424\n",
      "Epoch 7/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3759 - accuracy: 0.9312\n",
      "Epoch 8/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3572 - accuracy: 0.9429\n",
      "Epoch 9/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2949 - accuracy: 0.9609\n",
      "Epoch 10/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2612 - accuracy: 0.9619\n",
      "Epoch 11/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.2391 - accuracy: 0.9673\n",
      "Epoch 12/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2375 - accuracy: 0.9648\n",
      "Epoch 13/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2051 - accuracy: 0.9707\n",
      "Epoch 14/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1825 - accuracy: 0.9761\n",
      "Epoch 15/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1961 - accuracy: 0.9756\n",
      "Epoch 16/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1683 - accuracy: 0.9785\n",
      "Epoch 17/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1589 - accuracy: 0.9819\n",
      "Epoch 18/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2080 - accuracy: 0.9629\n",
      "Epoch 19/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1842 - accuracy: 0.9761\n",
      "Epoch 20/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1781 - accuracy: 0.9736\n",
      "Epoch 21/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1587 - accuracy: 0.9810\n",
      "Epoch 22/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.1670 - accuracy: 0.9741\n",
      "Epoch 23/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1490 - accuracy: 0.9814\n",
      "Epoch 24/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1308 - accuracy: 0.9844\n",
      "Epoch 25/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.1371 - accuracy: 0.9824\n",
      "Epoch 26/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1426 - accuracy: 0.9785\n",
      "Epoch 27/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1259 - accuracy: 0.9863\n",
      "Epoch 28/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1184 - accuracy: 0.9854\n",
      "Epoch 29/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1240 - accuracy: 0.9844\n",
      "Epoch 30/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.1200 - accuracy: 0.9824\n",
      "Epoch 31/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1108 - accuracy: 0.9888\n",
      "Epoch 32/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0991 - accuracy: 0.9907\n",
      "Epoch 33/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0934 - accuracy: 0.9912\n",
      "Epoch 34/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0999 - accuracy: 0.9907\n",
      "Epoch 35/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0971 - accuracy: 0.9893\n",
      "Epoch 36/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0908 - accuracy: 0.9902\n",
      "Epoch 37/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0833 - accuracy: 0.9946\n",
      "Epoch 38/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0774 - accuracy: 0.9961\n",
      "Epoch 39/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0825 - accuracy: 0.9927\n",
      "Epoch 40/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0782 - accuracy: 0.9946\n",
      "Epoch 41/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0806 - accuracy: 0.9902\n",
      "Epoch 42/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0829 - accuracy: 0.9902\n",
      "Epoch 43/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0712 - accuracy: 0.9951\n",
      "Epoch 44/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0741 - accuracy: 0.9932\n",
      "Epoch 45/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0674 - accuracy: 0.9956\n",
      "Epoch 46/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0740 - accuracy: 0.9922\n",
      "Epoch 47/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0632 - accuracy: 0.9971\n",
      "Epoch 48/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0730 - accuracy: 0.9912\n",
      "Epoch 49/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0636 - accuracy: 0.9951\n",
      "Epoch 50/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0644 - accuracy: 0.9932\n",
      "Epoch 51/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0685 - accuracy: 0.9927\n",
      "Epoch 52/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0635 - accuracy: 0.9956\n",
      "Epoch 53/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0628 - accuracy: 0.9941\n",
      "Epoch 54/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0593 - accuracy: 0.9946\n",
      "Epoch 55/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0639 - accuracy: 0.9941\n",
      "Epoch 56/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0593 - accuracy: 0.9956\n",
      "Epoch 57/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0559 - accuracy: 0.9971\n",
      "Epoch 58/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0642 - accuracy: 0.9937\n",
      "Epoch 59/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0583 - accuracy: 0.9937\n",
      "Epoch 60/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0587 - accuracy: 0.9956\n",
      "Epoch 61/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0508 - accuracy: 0.9971\n",
      "Epoch 62/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0583 - accuracy: 0.9932\n",
      "Epoch 63/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0556 - accuracy: 0.9946\n",
      "Epoch 64/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0609 - accuracy: 0.9927\n",
      "Epoch 65/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0508 - accuracy: 0.9985\n",
      "Epoch 66/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0539 - accuracy: 0.9951\n",
      "Epoch 67/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0572 - accuracy: 0.9961\n",
      "Epoch 68/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0535 - accuracy: 0.9956\n",
      "Epoch 69/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0545 - accuracy: 0.9941\n",
      "Epoch 70/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0509 - accuracy: 0.9971\n",
      "Epoch 71/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0489 - accuracy: 0.9961\n",
      "Epoch 72/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0507 - accuracy: 0.9956\n",
      "Epoch 73/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0563 - accuracy: 0.9927\n",
      "Epoch 74/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0478 - accuracy: 0.9976\n",
      "Epoch 75/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0515 - accuracy: 0.9961\n",
      "Epoch 76/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0519 - accuracy: 0.9951\n",
      "Epoch 77/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0518 - accuracy: 0.9946\n",
      "Epoch 78/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0511 - accuracy: 0.9971\n",
      "Epoch 79/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0506 - accuracy: 0.9946\n",
      "Epoch 80/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0502 - accuracy: 0.9980\n",
      "Epoch 1/80\n",
      " 1/64 [..............................] - ETA: 0s - loss: 0.0735 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0135s vs `on_train_batch_end` time: 0.0229s). Check your callbacks.\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1878 - accuracy: 0.9526\n",
      "Epoch 2/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.5954 - accuracy: 0.8691\n",
      "Epoch 3/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.5219 - accuracy: 0.8945\n",
      "Epoch 4/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.4041 - accuracy: 0.9312\n",
      "Epoch 5/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3538 - accuracy: 0.9463\n",
      "Epoch 6/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3292 - accuracy: 0.9414\n",
      "Epoch 7/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2735 - accuracy: 0.9629\n",
      "Epoch 8/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2710 - accuracy: 0.9604\n",
      "Epoch 9/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2341 - accuracy: 0.9683\n",
      "Epoch 10/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.2239 - accuracy: 0.9707\n",
      "Epoch 11/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2026 - accuracy: 0.9766\n",
      "Epoch 12/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1946 - accuracy: 0.9692\n",
      "Epoch 13/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1703 - accuracy: 0.9819\n",
      "Epoch 14/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1631 - accuracy: 0.9829\n",
      "Epoch 15/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2844 - accuracy: 0.9458\n",
      "Epoch 16/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2332 - accuracy: 0.9653\n",
      "Epoch 17/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3330 - accuracy: 0.9326\n",
      "Epoch 18/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.2632 - accuracy: 0.9629\n",
      "Epoch 19/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2268 - accuracy: 0.9751\n",
      "Epoch 20/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2099 - accuracy: 0.9785\n",
      "Epoch 21/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2877 - accuracy: 0.9551\n",
      "Epoch 22/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.2407 - accuracy: 0.9766\n",
      "Epoch 23/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2107 - accuracy: 0.9785\n",
      "Epoch 24/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1968 - accuracy: 0.9849\n",
      "Epoch 25/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1836 - accuracy: 0.9873\n",
      "Epoch 26/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1678 - accuracy: 0.9888\n",
      "Epoch 27/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1694 - accuracy: 0.9863\n",
      "Epoch 28/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1629 - accuracy: 0.9878\n",
      "Epoch 29/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1583 - accuracy: 0.9902\n",
      "Epoch 30/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1511 - accuracy: 0.9927\n",
      "Epoch 31/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1518 - accuracy: 0.9878\n",
      "Epoch 32/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1586 - accuracy: 0.9883\n",
      "Epoch 33/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.1445 - accuracy: 0.9888\n",
      "Epoch 34/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1388 - accuracy: 0.9917\n",
      "Epoch 35/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1320 - accuracy: 0.9932\n",
      "Epoch 36/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1337 - accuracy: 0.9907\n",
      "Epoch 37/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1462 - accuracy: 0.9849\n",
      "Epoch 38/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1264 - accuracy: 0.9937\n",
      "Epoch 39/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.1279 - accuracy: 0.9922\n",
      "Epoch 40/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1165 - accuracy: 0.9932\n",
      "Epoch 41/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1314 - accuracy: 0.9883\n",
      "Epoch 42/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1155 - accuracy: 0.9951\n",
      "Epoch 43/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1099 - accuracy: 0.9941\n",
      "Epoch 44/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1124 - accuracy: 0.9932\n",
      "Epoch 45/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1110 - accuracy: 0.9932\n",
      "Epoch 46/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.1120 - accuracy: 0.9922\n",
      "Epoch 47/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1135 - accuracy: 0.9902\n",
      "Epoch 48/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1067 - accuracy: 0.9932\n",
      "Epoch 49/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1045 - accuracy: 0.9951\n",
      "Epoch 50/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1175 - accuracy: 0.9893\n",
      "Epoch 51/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1071 - accuracy: 0.9927\n",
      "Epoch 52/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.1051 - accuracy: 0.9932\n",
      "Epoch 53/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0992 - accuracy: 0.9951\n",
      "Epoch 54/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1016 - accuracy: 0.9946\n",
      "Epoch 55/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1005 - accuracy: 0.9941\n",
      "Epoch 56/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1030 - accuracy: 0.9951\n",
      "Epoch 57/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.1014 - accuracy: 0.9946\n",
      "Epoch 58/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0993 - accuracy: 0.9922\n",
      "Epoch 59/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1036 - accuracy: 0.9927\n",
      "Epoch 60/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0953 - accuracy: 0.9956\n",
      "Epoch 61/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0995 - accuracy: 0.9937\n",
      "Epoch 62/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0942 - accuracy: 0.9951\n",
      "Epoch 63/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0907 - accuracy: 0.9976\n",
      "Epoch 64/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0925 - accuracy: 0.9937\n",
      "Epoch 65/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0965 - accuracy: 0.9932\n",
      "Epoch 66/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0866 - accuracy: 0.9966\n",
      "Epoch 67/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0898 - accuracy: 0.9946\n",
      "Epoch 68/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0909 - accuracy: 0.9927\n",
      "Epoch 69/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0986 - accuracy: 0.9922\n",
      "Epoch 70/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0877 - accuracy: 0.9961\n",
      "Epoch 71/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0909 - accuracy: 0.9932\n",
      "Epoch 72/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0881 - accuracy: 0.9956\n",
      "Epoch 73/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0905 - accuracy: 0.9941\n",
      "Epoch 74/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0857 - accuracy: 0.9971\n",
      "Epoch 75/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0849 - accuracy: 0.9966\n",
      "Epoch 76/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0840 - accuracy: 0.9971\n",
      "Epoch 77/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0819 - accuracy: 0.9971\n",
      "Epoch 78/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0835 - accuracy: 0.9961\n",
      "Epoch 79/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0861 - accuracy: 0.9941\n",
      "Epoch 80/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0830 - accuracy: 0.9951\n",
      "Epoch 1/80\n",
      " 1/64 [..............................] - ETA: 0s - loss: 0.0677 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0136s vs `on_train_batch_end` time: 0.0213s). Check your callbacks.\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3263 - accuracy: 0.9277\n",
      "Epoch 2/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.5463 - accuracy: 0.8965\n",
      "Epoch 3/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.4613 - accuracy: 0.9248\n",
      "Epoch 4/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.4425 - accuracy: 0.9224\n",
      "Epoch 5/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3624 - accuracy: 0.9487\n",
      "Epoch 6/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3448 - accuracy: 0.9541\n",
      "Epoch 7/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2737 - accuracy: 0.9692\n",
      "Epoch 8/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2394 - accuracy: 0.9727\n",
      "Epoch 9/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2263 - accuracy: 0.9746\n",
      "Epoch 10/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2583 - accuracy: 0.9590\n",
      "Epoch 11/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2998 - accuracy: 0.9644\n",
      "Epoch 12/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2551 - accuracy: 0.9697\n",
      "Epoch 13/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2271 - accuracy: 0.9761\n",
      "Epoch 14/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2067 - accuracy: 0.9790\n",
      "Epoch 15/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1843 - accuracy: 0.9839\n",
      "Epoch 16/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.1694 - accuracy: 0.9883\n",
      "Epoch 17/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1764 - accuracy: 0.9795\n",
      "Epoch 18/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1553 - accuracy: 0.9868\n",
      "Epoch 19/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1439 - accuracy: 0.9878\n",
      "Epoch 20/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1487 - accuracy: 0.9829\n",
      "Epoch 21/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1310 - accuracy: 0.9883\n",
      "Epoch 22/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1225 - accuracy: 0.9912\n",
      "Epoch 23/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1298 - accuracy: 0.9868\n",
      "Epoch 24/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1401 - accuracy: 0.9810\n",
      "Epoch 25/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1184 - accuracy: 0.9883\n",
      "Epoch 26/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1111 - accuracy: 0.9912\n",
      "Epoch 27/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1082 - accuracy: 0.9917\n",
      "Epoch 28/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1240 - accuracy: 0.9868\n",
      "Epoch 29/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1290 - accuracy: 0.9814\n",
      "Epoch 30/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1134 - accuracy: 0.9897\n",
      "Epoch 31/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1155 - accuracy: 0.9863\n",
      "Epoch 32/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0977 - accuracy: 0.9932\n",
      "Epoch 33/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0969 - accuracy: 0.9927\n",
      "Epoch 34/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0922 - accuracy: 0.9922\n",
      "Epoch 35/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0837 - accuracy: 0.9966\n",
      "Epoch 36/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0939 - accuracy: 0.9907\n",
      "Epoch 37/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0810 - accuracy: 0.9941\n",
      "Epoch 38/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0841 - accuracy: 0.9917\n",
      "Epoch 39/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0853 - accuracy: 0.9927\n",
      "Epoch 40/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0817 - accuracy: 0.9927\n",
      "Epoch 41/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0834 - accuracy: 0.9912\n",
      "Epoch 42/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0733 - accuracy: 0.9946\n",
      "Epoch 43/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0771 - accuracy: 0.9937\n",
      "Epoch 44/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0779 - accuracy: 0.9941\n",
      "Epoch 45/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0802 - accuracy: 0.9917\n",
      "Epoch 46/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0909 - accuracy: 0.9893\n",
      "Epoch 47/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0740 - accuracy: 0.9932\n",
      "Epoch 48/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0742 - accuracy: 0.9917\n",
      "Epoch 49/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0695 - accuracy: 0.9946\n",
      "Epoch 50/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0712 - accuracy: 0.9956\n",
      "Epoch 51/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0755 - accuracy: 0.9907\n",
      "Epoch 52/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0863 - accuracy: 0.9897\n",
      "Epoch 53/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0752 - accuracy: 0.9902\n",
      "Epoch 54/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0746 - accuracy: 0.9946\n",
      "Epoch 55/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0687 - accuracy: 0.9966\n",
      "Epoch 56/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0779 - accuracy: 0.9917\n",
      "Epoch 57/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0635 - accuracy: 0.9980\n",
      "Epoch 58/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0667 - accuracy: 0.9956\n",
      "Epoch 59/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0622 - accuracy: 0.9951\n",
      "Epoch 60/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0637 - accuracy: 0.9966\n",
      "Epoch 61/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0645 - accuracy: 0.9966\n",
      "Epoch 62/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0607 - accuracy: 0.9966\n",
      "Epoch 63/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0685 - accuracy: 0.9941\n",
      "Epoch 64/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0612 - accuracy: 0.9961\n",
      "Epoch 65/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0604 - accuracy: 0.9961\n",
      "Epoch 66/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0594 - accuracy: 0.9976\n",
      "Epoch 67/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0589 - accuracy: 0.9961\n",
      "Epoch 68/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0620 - accuracy: 0.9951\n",
      "Epoch 69/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0590 - accuracy: 0.9966\n",
      "Epoch 70/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0557 - accuracy: 0.9976\n",
      "Epoch 71/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0651 - accuracy: 0.9941\n",
      "Epoch 72/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0596 - accuracy: 0.9961\n",
      "Epoch 73/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0553 - accuracy: 0.9966\n",
      "Epoch 74/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0687 - accuracy: 0.9912\n",
      "Epoch 75/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0577 - accuracy: 0.9966\n",
      "Epoch 76/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0599 - accuracy: 0.9961\n",
      "Epoch 77/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0609 - accuracy: 0.9956\n",
      "Epoch 78/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0580 - accuracy: 0.9971\n",
      "Epoch 79/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0625 - accuracy: 0.9946\n",
      "Epoch 80/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0542 - accuracy: 0.9961\n",
      "Epoch 1/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3041 - accuracy: 0.9258\n",
      "Epoch 2/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.5545 - accuracy: 0.9048\n",
      "Epoch 3/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.5425 - accuracy: 0.9004\n",
      "Epoch 4/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3695 - accuracy: 0.9531\n",
      "Epoch 5/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3814 - accuracy: 0.9424\n",
      "Epoch 6/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3472 - accuracy: 0.9556\n",
      "Epoch 7/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2926 - accuracy: 0.9624\n",
      "Epoch 8/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2403 - accuracy: 0.9751\n",
      "Epoch 9/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2153 - accuracy: 0.9800\n",
      "Epoch 10/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2082 - accuracy: 0.9751\n",
      "Epoch 11/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1887 - accuracy: 0.9810\n",
      "Epoch 12/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1609 - accuracy: 0.9878\n",
      "Epoch 13/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1686 - accuracy: 0.9795\n",
      "Epoch 14/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1536 - accuracy: 0.9858\n",
      "Epoch 15/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1523 - accuracy: 0.9795\n",
      "Epoch 16/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1444 - accuracy: 0.9829\n",
      "Epoch 17/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1352 - accuracy: 0.9854\n",
      "Epoch 18/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1327 - accuracy: 0.9873\n",
      "Epoch 19/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1323 - accuracy: 0.9863\n",
      "Epoch 20/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1276 - accuracy: 0.9863\n",
      "Epoch 21/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1117 - accuracy: 0.9878\n",
      "Epoch 22/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1066 - accuracy: 0.9893\n",
      "Epoch 23/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1060 - accuracy: 0.9873\n",
      "Epoch 24/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1051 - accuracy: 0.9883\n",
      "Epoch 25/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0960 - accuracy: 0.9922\n",
      "Epoch 26/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1001 - accuracy: 0.9888\n",
      "Epoch 27/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1088 - accuracy: 0.9878\n",
      "Epoch 28/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0972 - accuracy: 0.9912\n",
      "Epoch 29/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0961 - accuracy: 0.9897\n",
      "Epoch 30/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0985 - accuracy: 0.9897\n",
      "Epoch 31/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0904 - accuracy: 0.9912\n",
      "Epoch 32/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0879 - accuracy: 0.9917\n",
      "Epoch 33/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0953 - accuracy: 0.9883\n",
      "Epoch 34/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0924 - accuracy: 0.9883\n",
      "Epoch 35/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0847 - accuracy: 0.9917\n",
      "Epoch 36/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0817 - accuracy: 0.9941\n",
      "Epoch 37/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0820 - accuracy: 0.9922\n",
      "Epoch 38/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0863 - accuracy: 0.9907\n",
      "Epoch 39/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0835 - accuracy: 0.9912\n",
      "Epoch 40/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0790 - accuracy: 0.9907\n",
      "Epoch 41/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0709 - accuracy: 0.9932\n",
      "Epoch 42/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0665 - accuracy: 0.9951\n",
      "Epoch 43/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0739 - accuracy: 0.9902\n",
      "Epoch 44/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0702 - accuracy: 0.9927\n",
      "Epoch 45/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0682 - accuracy: 0.9912\n",
      "Epoch 46/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0702 - accuracy: 0.9937\n",
      "Epoch 47/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0657 - accuracy: 0.9922\n",
      "Epoch 48/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0603 - accuracy: 0.9976\n",
      "Epoch 49/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0605 - accuracy: 0.9951\n",
      "Epoch 50/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0611 - accuracy: 0.9956\n",
      "Epoch 51/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0687 - accuracy: 0.9922\n",
      "Epoch 52/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0608 - accuracy: 0.9951\n",
      "Epoch 53/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0606 - accuracy: 0.9956\n",
      "Epoch 54/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0567 - accuracy: 0.9961\n",
      "Epoch 55/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0564 - accuracy: 0.9951\n",
      "Epoch 56/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0542 - accuracy: 0.9966\n",
      "Epoch 57/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0549 - accuracy: 0.9961\n",
      "Epoch 58/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0546 - accuracy: 0.9966\n",
      "Epoch 59/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0494 - accuracy: 0.9976\n",
      "Epoch 60/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0535 - accuracy: 0.9971\n",
      "Epoch 61/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0547 - accuracy: 0.9946\n",
      "Epoch 62/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0552 - accuracy: 0.9956\n",
      "Epoch 63/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0543 - accuracy: 0.9961\n",
      "Epoch 64/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0537 - accuracy: 0.9951\n",
      "Epoch 65/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0564 - accuracy: 0.9951\n",
      "Epoch 66/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0502 - accuracy: 0.9966\n",
      "Epoch 67/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0510 - accuracy: 0.9976\n",
      "Epoch 68/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0491 - accuracy: 0.9980\n",
      "Epoch 69/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0481 - accuracy: 0.9971\n",
      "Epoch 70/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0496 - accuracy: 0.9951\n",
      "Epoch 71/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0456 - accuracy: 0.9980\n",
      "Epoch 72/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0484 - accuracy: 0.9971\n",
      "Epoch 73/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0476 - accuracy: 0.9985\n",
      "Epoch 74/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0485 - accuracy: 0.9961\n",
      "Epoch 75/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0505 - accuracy: 0.9956\n",
      "Epoch 76/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0482 - accuracy: 0.9976\n",
      "Epoch 77/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0455 - accuracy: 0.9971\n",
      "Epoch 78/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0476 - accuracy: 0.9966\n",
      "Epoch 79/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0482 - accuracy: 0.9956\n",
      "Epoch 80/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0480 - accuracy: 0.9980\n",
      "Epoch 1/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3432 - accuracy: 0.9292\n",
      "Epoch 2/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.8325 - accuracy: 0.8501\n",
      "Epoch 3/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 1.0079 - accuracy: 0.8530\n",
      "Epoch 4/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.9780 - accuracy: 0.8799\n",
      "Epoch 5/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.6704 - accuracy: 0.9517\n",
      "Epoch 6/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.5840 - accuracy: 0.9580\n",
      "Epoch 7/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.5039 - accuracy: 0.9678\n",
      "Epoch 8/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.4519 - accuracy: 0.9727\n",
      "Epoch 9/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.4203 - accuracy: 0.9751\n",
      "Epoch 10/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.5052 - accuracy: 0.9482\n",
      "Epoch 11/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.4819 - accuracy: 0.9536\n",
      "Epoch 12/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.4356 - accuracy: 0.9639\n",
      "Epoch 13/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3555 - accuracy: 0.9775\n",
      "Epoch 14/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3596 - accuracy: 0.9751\n",
      "Epoch 15/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3147 - accuracy: 0.9844\n",
      "Epoch 16/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3007 - accuracy: 0.9795\n",
      "Epoch 17/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2920 - accuracy: 0.9790\n",
      "Epoch 18/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2670 - accuracy: 0.9844\n",
      "Epoch 19/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2505 - accuracy: 0.9902\n",
      "Epoch 20/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.2571 - accuracy: 0.9824\n",
      "Epoch 21/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2358 - accuracy: 0.9863\n",
      "Epoch 22/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2207 - accuracy: 0.9888\n",
      "Epoch 23/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2115 - accuracy: 0.9863\n",
      "Epoch 24/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2022 - accuracy: 0.9902\n",
      "Epoch 25/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.2039 - accuracy: 0.9854\n",
      "Epoch 26/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1977 - accuracy: 0.9878\n",
      "Epoch 27/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1748 - accuracy: 0.9922\n",
      "Epoch 28/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1737 - accuracy: 0.9902\n",
      "Epoch 29/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1786 - accuracy: 0.9863\n",
      "Epoch 30/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1721 - accuracy: 0.9907\n",
      "Epoch 31/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1708 - accuracy: 0.9883\n",
      "Epoch 32/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1580 - accuracy: 0.9917\n",
      "Epoch 33/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1505 - accuracy: 0.9927\n",
      "Epoch 34/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1482 - accuracy: 0.9937\n",
      "Epoch 35/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1375 - accuracy: 0.9961\n",
      "Epoch 36/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1444 - accuracy: 0.9897\n",
      "Epoch 37/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1349 - accuracy: 0.9951\n",
      "Epoch 38/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1376 - accuracy: 0.9912\n",
      "Epoch 39/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1412 - accuracy: 0.9893\n",
      "Epoch 40/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1367 - accuracy: 0.9917\n",
      "Epoch 41/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1273 - accuracy: 0.9941\n",
      "Epoch 42/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1308 - accuracy: 0.9922\n",
      "Epoch 43/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1254 - accuracy: 0.9951\n",
      "Epoch 44/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1204 - accuracy: 0.9946\n",
      "Epoch 45/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1181 - accuracy: 0.9946\n",
      "Epoch 46/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1356 - accuracy: 0.9858\n",
      "Epoch 47/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1329 - accuracy: 0.9883\n",
      "Epoch 48/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1226 - accuracy: 0.9927\n",
      "Epoch 49/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1206 - accuracy: 0.9922\n",
      "Epoch 50/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1219 - accuracy: 0.9917\n",
      "Epoch 51/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1156 - accuracy: 0.9937\n",
      "Epoch 52/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1093 - accuracy: 0.9956\n",
      "Epoch 53/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1119 - accuracy: 0.9951\n",
      "Epoch 54/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.1079 - accuracy: 0.9946\n",
      "Epoch 55/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1117 - accuracy: 0.9946\n",
      "Epoch 56/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1177 - accuracy: 0.9937\n",
      "Epoch 57/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1056 - accuracy: 0.9941\n",
      "Epoch 58/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1106 - accuracy: 0.9907\n",
      "Epoch 59/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1009 - accuracy: 0.9971\n",
      "Epoch 60/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1005 - accuracy: 0.9956\n",
      "Epoch 61/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1017 - accuracy: 0.9951\n",
      "Epoch 62/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1039 - accuracy: 0.9966\n",
      "Epoch 63/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1002 - accuracy: 0.9961\n",
      "Epoch 64/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1029 - accuracy: 0.9946\n",
      "Epoch 65/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1003 - accuracy: 0.9956\n",
      "Epoch 66/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0984 - accuracy: 0.9956\n",
      "Epoch 67/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1034 - accuracy: 0.9951\n",
      "Epoch 68/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0991 - accuracy: 0.9946\n",
      "Epoch 69/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1046 - accuracy: 0.9927\n",
      "Epoch 70/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0967 - accuracy: 0.9951\n",
      "Epoch 71/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1008 - accuracy: 0.9956\n",
      "Epoch 72/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0950 - accuracy: 0.9971\n",
      "Epoch 73/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0939 - accuracy: 0.9966\n",
      "Epoch 74/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0930 - accuracy: 0.9956\n",
      "Epoch 75/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0945 - accuracy: 0.9961\n",
      "Epoch 76/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0907 - accuracy: 0.9971\n",
      "Epoch 77/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0940 - accuracy: 0.9961\n",
      "Epoch 78/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0877 - accuracy: 0.9985\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0925 - accuracy: 0.9956\n",
      "Epoch 80/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0905 - accuracy: 0.9976\n",
      "Epoch 1/80\n",
      " 1/64 [..............................] - ETA: 0s - loss: 0.1258 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 0.0212s). Check your callbacks.\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3228 - accuracy: 0.9380\n",
      "Epoch 2/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.5727 - accuracy: 0.9058\n",
      "Epoch 3/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.5814 - accuracy: 0.9160\n",
      "Epoch 4/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.4348 - accuracy: 0.9546\n",
      "Epoch 5/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3617 - accuracy: 0.9663\n",
      "Epoch 6/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3084 - accuracy: 0.9712\n",
      "Epoch 7/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2699 - accuracy: 0.9775\n",
      "Epoch 8/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2445 - accuracy: 0.9731\n",
      "Epoch 9/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2208 - accuracy: 0.9771\n",
      "Epoch 10/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2157 - accuracy: 0.9771\n",
      "Epoch 11/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2348 - accuracy: 0.9731\n",
      "Epoch 12/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2006 - accuracy: 0.9805\n",
      "Epoch 13/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1963 - accuracy: 0.9780\n",
      "Epoch 14/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1647 - accuracy: 0.9878\n",
      "Epoch 15/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1570 - accuracy: 0.9868\n",
      "Epoch 16/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1515 - accuracy: 0.9878\n",
      "Epoch 17/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1482 - accuracy: 0.9893\n",
      "Epoch 18/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1335 - accuracy: 0.9883\n",
      "Epoch 19/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1304 - accuracy: 0.9868\n",
      "Epoch 20/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1307 - accuracy: 0.9868\n",
      "Epoch 21/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1283 - accuracy: 0.9897\n",
      "Epoch 22/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1218 - accuracy: 0.9878\n",
      "Epoch 23/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1083 - accuracy: 0.9907\n",
      "Epoch 24/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1020 - accuracy: 0.9941\n",
      "Epoch 25/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1182 - accuracy: 0.9868\n",
      "Epoch 26/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1057 - accuracy: 0.9907\n",
      "Epoch 27/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1212 - accuracy: 0.9819\n",
      "Epoch 28/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1068 - accuracy: 0.9893\n",
      "Epoch 29/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1017 - accuracy: 0.9922\n",
      "Epoch 30/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0998 - accuracy: 0.9897\n",
      "Epoch 31/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0902 - accuracy: 0.9937\n",
      "Epoch 32/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0915 - accuracy: 0.9907\n",
      "Epoch 33/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0844 - accuracy: 0.9941\n",
      "Epoch 34/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0893 - accuracy: 0.9907\n",
      "Epoch 35/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0799 - accuracy: 0.9941\n",
      "Epoch 36/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0857 - accuracy: 0.9897\n",
      "Epoch 37/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1103 - accuracy: 0.9829\n",
      "Epoch 38/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1107 - accuracy: 0.9834\n",
      "Epoch 39/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0887 - accuracy: 0.9941\n",
      "Epoch 40/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0835 - accuracy: 0.9927\n",
      "Epoch 41/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0825 - accuracy: 0.9941\n",
      "Epoch 42/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0792 - accuracy: 0.9941\n",
      "Epoch 43/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0806 - accuracy: 0.9941\n",
      "Epoch 44/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0862 - accuracy: 0.9907\n",
      "Epoch 45/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0758 - accuracy: 0.9966\n",
      "Epoch 46/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0756 - accuracy: 0.9941\n",
      "Epoch 47/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0710 - accuracy: 0.9971\n",
      "Epoch 48/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0750 - accuracy: 0.9941\n",
      "Epoch 49/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0690 - accuracy: 0.9941\n",
      "Epoch 50/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0777 - accuracy: 0.9927\n",
      "Epoch 51/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0685 - accuracy: 0.9951\n",
      "Epoch 52/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0691 - accuracy: 0.9956\n",
      "Epoch 53/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0713 - accuracy: 0.9951\n",
      "Epoch 54/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0662 - accuracy: 0.9956\n",
      "Epoch 55/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0717 - accuracy: 0.9932\n",
      "Epoch 56/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0659 - accuracy: 0.9937\n",
      "Epoch 57/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0657 - accuracy: 0.9956\n",
      "Epoch 58/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0647 - accuracy: 0.9951\n",
      "Epoch 59/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0637 - accuracy: 0.9966\n",
      "Epoch 60/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0620 - accuracy: 0.9971\n",
      "Epoch 61/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0592 - accuracy: 0.9976\n",
      "Epoch 62/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0635 - accuracy: 0.9941\n",
      "Epoch 63/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0620 - accuracy: 0.9956\n",
      "Epoch 64/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0650 - accuracy: 0.9941\n",
      "Epoch 65/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0593 - accuracy: 0.9961\n",
      "Epoch 66/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0604 - accuracy: 0.9971\n",
      "Epoch 67/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0614 - accuracy: 0.9956\n",
      "Epoch 68/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0589 - accuracy: 0.9961\n",
      "Epoch 69/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0593 - accuracy: 0.9961\n",
      "Epoch 70/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0566 - accuracy: 0.9976\n",
      "Epoch 71/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0589 - accuracy: 0.9966\n",
      "Epoch 72/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0609 - accuracy: 0.9951\n",
      "Epoch 73/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0665 - accuracy: 0.9937\n",
      "Epoch 74/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0568 - accuracy: 0.9961\n",
      "Epoch 75/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0542 - accuracy: 0.9976\n",
      "Epoch 76/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0588 - accuracy: 0.9956\n",
      "Epoch 77/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0564 - accuracy: 0.9966\n",
      "Epoch 78/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0576 - accuracy: 0.9956\n",
      "Epoch 79/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0525 - accuracy: 0.9971\n",
      "Epoch 80/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0581 - accuracy: 0.9951\n",
      "Epoch 1/80\n",
      " 1/64 [..............................] - ETA: 0s - loss: 0.0612 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 0.0214s). Check your callbacks.\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3393 - accuracy: 0.9336\n",
      "Epoch 2/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.6846 - accuracy: 0.8931\n",
      "Epoch 3/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.5267 - accuracy: 0.9341\n",
      "Epoch 4/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.4030 - accuracy: 0.9590\n",
      "Epoch 5/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.3410 - accuracy: 0.9683\n",
      "Epoch 6/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.2910 - accuracy: 0.9746\n",
      "Epoch 7/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2601 - accuracy: 0.9795\n",
      "Epoch 8/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2666 - accuracy: 0.9678\n",
      "Epoch 9/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2220 - accuracy: 0.9824\n",
      "Epoch 10/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.2040 - accuracy: 0.9819\n",
      "Epoch 11/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1782 - accuracy: 0.9873\n",
      "Epoch 12/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1639 - accuracy: 0.9893\n",
      "Epoch 13/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1677 - accuracy: 0.9849\n",
      "Epoch 14/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1493 - accuracy: 0.9878\n",
      "Epoch 15/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1511 - accuracy: 0.9858\n",
      "Epoch 16/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1589 - accuracy: 0.9780\n",
      "Epoch 17/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1417 - accuracy: 0.9883\n",
      "Epoch 18/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1415 - accuracy: 0.9829\n",
      "Epoch 19/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1497 - accuracy: 0.9805\n",
      "Epoch 20/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1217 - accuracy: 0.9897\n",
      "Epoch 21/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1211 - accuracy: 0.9893\n",
      "Epoch 22/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1142 - accuracy: 0.9932\n",
      "Epoch 23/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1137 - accuracy: 0.9883\n",
      "Epoch 24/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1116 - accuracy: 0.9893\n",
      "Epoch 25/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1037 - accuracy: 0.9907\n",
      "Epoch 26/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0997 - accuracy: 0.9922\n",
      "Epoch 27/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1000 - accuracy: 0.9917\n",
      "Epoch 28/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0928 - accuracy: 0.9941\n",
      "Epoch 29/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0894 - accuracy: 0.9937\n",
      "Epoch 30/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0885 - accuracy: 0.9937\n",
      "Epoch 31/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0883 - accuracy: 0.9922\n",
      "Epoch 32/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0811 - accuracy: 0.9946\n",
      "Epoch 33/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0800 - accuracy: 0.9927\n",
      "Epoch 34/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0738 - accuracy: 0.9951\n",
      "Epoch 35/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0751 - accuracy: 0.9961\n",
      "Epoch 36/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0674 - accuracy: 0.9961\n",
      "Epoch 37/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0719 - accuracy: 0.9961\n",
      "Epoch 38/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0706 - accuracy: 0.9956\n",
      "Epoch 39/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0650 - accuracy: 0.9966\n",
      "Epoch 40/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0699 - accuracy: 0.9961\n",
      "Epoch 41/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0723 - accuracy: 0.9941\n",
      "Epoch 42/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0750 - accuracy: 0.9937\n",
      "Epoch 43/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0647 - accuracy: 0.9961\n",
      "Epoch 44/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0664 - accuracy: 0.9946\n",
      "Epoch 45/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0607 - accuracy: 0.9971\n",
      "Epoch 46/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0619 - accuracy: 0.9951\n",
      "Epoch 47/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0656 - accuracy: 0.9966\n",
      "Epoch 48/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0634 - accuracy: 0.9917\n",
      "Epoch 49/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0592 - accuracy: 0.9971\n",
      "Epoch 50/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0561 - accuracy: 0.9966\n",
      "Epoch 51/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0538 - accuracy: 0.9976\n",
      "Epoch 52/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0578 - accuracy: 0.9966\n",
      "Epoch 53/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0603 - accuracy: 0.9966\n",
      "Epoch 54/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0582 - accuracy: 0.9951\n",
      "Epoch 55/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0518 - accuracy: 0.9995\n",
      "Epoch 56/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0522 - accuracy: 0.9966\n",
      "Epoch 57/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0573 - accuracy: 0.9951\n",
      "Epoch 58/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0523 - accuracy: 0.9980\n",
      "Epoch 59/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0500 - accuracy: 0.9980\n",
      "Epoch 60/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0587 - accuracy: 0.9956\n",
      "Epoch 61/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0499 - accuracy: 0.9966\n",
      "Epoch 62/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0546 - accuracy: 0.9946\n",
      "Epoch 63/80\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0540 - accuracy: 0.9961\n",
      "Epoch 64/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0549 - accuracy: 0.9966\n",
      "Epoch 65/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0525 - accuracy: 0.9966\n",
      "Epoch 66/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0537 - accuracy: 0.9951\n",
      "Epoch 67/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0515 - accuracy: 0.9961\n",
      "Epoch 68/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0484 - accuracy: 0.9966\n",
      "Epoch 69/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0547 - accuracy: 0.9932\n",
      "Epoch 70/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0478 - accuracy: 0.9980\n",
      "Epoch 71/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0462 - accuracy: 0.9985\n",
      "Epoch 72/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0446 - accuracy: 0.9990\n",
      "Epoch 73/80\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0429 - accuracy: 0.9990\n",
      "Epoch 74/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0498 - accuracy: 0.9961\n",
      "Epoch 75/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0532 - accuracy: 0.9946\n",
      "Epoch 76/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0493 - accuracy: 0.9961\n",
      "Epoch 77/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0518 - accuracy: 0.9971\n",
      "Epoch 78/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0496 - accuracy: 0.9951\n",
      "Epoch 79/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0478 - accuracy: 0.9961\n",
      "Epoch 80/80\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0513 - accuracy: 0.9951\n"
     ]
    }
   ],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "\n",
    "# 이미지 증식 사용\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  \n",
    "    zoom_range = 0.1, \n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1)\n",
    "\n",
    "#model = create_cnn_model() #앞에거에 이어서 학습\n",
    "epochs=80\n",
    "\n",
    "#model.fit(x_train, y_train, epochs=50)\n",
    "for i in range(0,10):\n",
    "    history = model.fit(\n",
    "      datagen.flow(x_train2, y_train, batch_size=32),\n",
    "      epochs=epochs, \n",
    "      steps_per_epoch = x_train2.shape[0]//32,\n",
    "      callbacks=[annealer], \n",
    "      verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "x_t_edit=x_test\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = np.repeat(x_test, 3, axis=1)\n",
    "x_test2 = np.repeat(x_test1, 3, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2049</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2051</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2053</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2054</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2055</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2057</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2058</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2060</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2061</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2062</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2064</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2068</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2069</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2070</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2071</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2072</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2073</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2074</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2077</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2078</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2079</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2080</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2082</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2084</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2086</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2087</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2088</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2089</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2091</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2092</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2093</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2095</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2096</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2097</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2098</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  digit\n",
       "0   2049      6\n",
       "1   2050      9\n",
       "2   2051      8\n",
       "3   2052      0\n",
       "4   2053      3\n",
       "5   2054      7\n",
       "6   2055      5\n",
       "7   2056      3\n",
       "8   2057      4\n",
       "9   2058      4\n",
       "10  2059      1\n",
       "11  2060      5\n",
       "12  2061      7\n",
       "13  2062      5\n",
       "14  2063      1\n",
       "15  2064      8\n",
       "16  2065      1\n",
       "17  2066      6\n",
       "18  2067      1\n",
       "19  2068      4\n",
       "20  2069      5\n",
       "21  2070      9\n",
       "22  2071      7\n",
       "23  2072      7\n",
       "24  2073      3\n",
       "25  2074      7\n",
       "26  2075      0\n",
       "27  2076      1\n",
       "28  2077      9\n",
       "29  2078      8\n",
       "30  2079      8\n",
       "31  2080      8\n",
       "32  2081      0\n",
       "33  2082      6\n",
       "34  2083      0\n",
       "35  2084      4\n",
       "36  2085      1\n",
       "37  2086      5\n",
       "38  2087      2\n",
       "39  2088      4\n",
       "40  2089      2\n",
       "41  2090      1\n",
       "42  2091      8\n",
       "43  2092      2\n",
       "44  2093      3\n",
       "45  2094      0\n",
       "46  2095      3\n",
       "47  2096      6\n",
       "48  2097      2\n",
       "49  2098      5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('data/submission.csv')\n",
    "submission['digit'] = np.argmax(model.predict(x_test2), axis=1)\n",
    "submission.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('앞단 100 뒷단 80으로 10번.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n"
     ]
    }
   ],
   "source": [
    "threshold=140 #임계값\n",
    "for i in range(0,20480):\n",
    "    if(i%3000==0):\n",
    "        print(i)\n",
    "    for j in range(0,28):\n",
    "        for k in range(0,28): \n",
    "            if(x_t_edit[i][j][k][0]<=threshold):\n",
    "                x_t_edit[i][j][k][0]=0\n",
    "            else:\n",
    "                x_t_edit[i][j][k][0]=255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t_edit1 = np.repeat(x_t_edit, 3, axis=1)\n",
    "x_t_edit2 = np.repeat(x_t_edit1, 3, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2049</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2051</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2052</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2053</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2054</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2055</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2056</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2057</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2058</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2059</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2060</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2062</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2063</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2064</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2067</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2068</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2069</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2070</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2071</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2072</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2073</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2074</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2075</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2076</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2077</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2078</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2079</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2080</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2081</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2082</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2083</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2084</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2085</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2086</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2087</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2088</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2089</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2090</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2091</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2092</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2093</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2094</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2095</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2096</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2097</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2098</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  digit\n",
       "0   2049      2\n",
       "1   2050      8\n",
       "2   2051      2\n",
       "3   2052      8\n",
       "4   2053      8\n",
       "5   2054      8\n",
       "6   2055      8\n",
       "7   2056      2\n",
       "8   2057      2\n",
       "9   2058      8\n",
       "10  2059      2\n",
       "11  2060      8\n",
       "12  2061      2\n",
       "13  2062      8\n",
       "14  2063      5\n",
       "15  2064      8\n",
       "16  2065      2\n",
       "17  2066      2\n",
       "18  2067      5\n",
       "19  2068      2\n",
       "20  2069      3\n",
       "21  2070      8\n",
       "22  2071      8\n",
       "23  2072      2\n",
       "24  2073      3\n",
       "25  2074      8\n",
       "26  2075      8\n",
       "27  2076      9\n",
       "28  2077      8\n",
       "29  2078      2\n",
       "30  2079      2\n",
       "31  2080      2\n",
       "32  2081      8\n",
       "33  2082      2\n",
       "34  2083      2\n",
       "35  2084      8\n",
       "36  2085      2\n",
       "37  2086      2\n",
       "38  2087      2\n",
       "39  2088      8\n",
       "40  2089      2\n",
       "41  2090      2\n",
       "42  2091      8\n",
       "43  2092      8\n",
       "44  2093      3\n",
       "45  2094      2\n",
       "46  2095      9\n",
       "47  2096      8\n",
       "48  2097      2\n",
       "49  2098      8"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission2 = pd.read_csv('data/submission.csv')\n",
    "submission2['digit'] = np.argmax(model.predict(x_t_edit2), axis=1)\n",
    "submission2.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#head만봐도 정확도가 너무 안좋아서 따로 저장 안하는게 나을듯?\n",
    "submission2.to_csv('두번 이어서 훈련_이진화otest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
